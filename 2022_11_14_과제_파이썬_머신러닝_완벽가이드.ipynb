{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOAqcPGid4UddR4ECja7R0F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyoons/ESAA/blob/main/2022_11_14_%EA%B3%BC%EC%A0%9C_%ED%8C%8C%EC%9D%B4%EC%8D%AC_%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EC%99%84%EB%B2%BD%EA%B0%80%EC%9D%B4%EB%93%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">**06. XGBoost(xEtra Gradient Boost)**\n",
        "\n",
        "**XGBoost 개요**\n",
        "\n",
        "GBM 기반. 회귀, 분류 영역에서 뛰어난 예측 성능, 빠른 수행 시간, 과적합 규제, 나무 가지치기, 내장된 교차 검증, 결손값 자체 처리의 장점.\n",
        "\n",
        "**XGBoost 설치하기**\n"
      ],
      "metadata": {
        "id": "R0GlMMzv7wTu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Pl9jyGs07usQ"
      },
      "outputs": [],
      "source": [
        "import xgboost as xgb\n",
        "from xgboost import XGBClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**파이썬 래퍼 XGBoost 하이퍼 파라미터**\n",
        "\n",
        "XGBooost는 GBM과 유사한 하이퍼 파라미터를 갖고 여기에 조기 중단, 과적합 규제를 위한 하이퍼 파라미터 등이 추가됨. 파이썬 래퍼 XGBoost 모듈과 사이킷런 래퍼 XGBoost 모듈의 일부 하이퍼 파라미터는 약간 달라서 주의가 필요. \n",
        "\n",
        "파이썬 래퍼 XGBoost 하이퍼 파라미터를 유형별로 나눠보면\n",
        "<br/>일반 파라미터 : 디폴트를 바꾸는 경우 거의 x\n",
        "<br/>부스터 파라미터 : 트리 최적화, 부스팅, regularization 등 관련 파라미터 지칭\n",
        "<br/>학습 태스크 파라미터 : 학습 수행 시의 지표 설정\n",
        "\n",
        "대부분의 하이퍼 파라미터는 Booster 파라미터에 속한다.\n",
        "\n",
        "* 주요 일반 파라미터\n",
        "<br/>booster : gbtree 도는 gblinear 선택. 디폴트는 gbtree\n",
        "<br/>silent : 디폴트는 0, 출력 메시지 나타내고 싶지 않을 때 1\n",
        "<br/>nthread : cpu의 실행 스레드 개수 조정\n",
        "\n",
        "* 주요 부스터 파라미터\n",
        "<br/>eta : GBM의 학습률\n",
        "<br/>num_boost_rounds : GBM의 n_estimators\n",
        "<br/>min_child_weight[default=1] : 가지를 나눌지 결정, 과적합 조절\n",
        "<br/>gamma[default=0, alias: min_split_loss] : 리프 노드를 추가적으로 나눌지 결정, 최소 손실 감소 값\n",
        "<br/>max_depth\n",
        "<br/>sub_sample\n",
        "<br/>colsample_bytree : GBM의 max_features\n",
        "<br/>lambda : L2 Regularization 적용 값. 클수록 과적합 감소 효과\n",
        "<br/>alpha : L1 Regularizatiobn 적용 값. 과적합 감소 효과.\n",
        "<br/>scale_pos_weight : 특정 값으로 치우친 비대칭 클래스로 구성된 데이터 균형 유지.\n",
        "\n",
        "* 학습 태스크 파라미터\n",
        "<br/>objective : 최솟값을 가져야할 손실 함수 정의\n",
        "<br/>binary:logistic : 이진 분류\n",
        "<br/>multi:softmax : 다중 분류\n",
        "<br/>multi:softprob : multi:softmax와 유사하나 개별 레이블 클래스의 해당되는 예측 확률 반환\n",
        "<br/>eval_metric : 검증에 사용되는 함수 적용. 기본값은 회귀는 rmse, 분류는 error\n",
        "\n",
        "과적합 문제가 심각하다면 eta값을 낮추고 num_round를 높이거나, max_depth 낮추거나, min_child_weight 높이거나, gamma 높이거나, subsample과 colsample_bytree 조정하는 방법 등이 있다.\n",
        "\n",
        "XGBoost는 자체적으로 교차 검증, 성능 평가, 피처 중요도 등의 시각화 기능을 갖고 있다. 수행 속도를 향상시키기 위한 조기 중단 기능도 있다. 예를 들어 n_estimators를 200으로 설정하고 조기 중단 파라미터 값을 50으로 설정하면 200회까지 부스팅 반복하다가 50회를 반복하는 동안 학습 오류가 감소하지 않으면 종료한다. 버전 0.9니까 책과 결과 다를 수 있음."
      ],
      "metadata": {
        "id": "tOPgSQyn9BRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost\n",
        "\n",
        "print(xgboost.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NsFZLjNBBhnj",
        "outputId": "cb0c2809-5416-4a94-a570-6ffb7ef41c33"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.90\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "N7P6BlbdB-v0"
      }
    }
  ]
}