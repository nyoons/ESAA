{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPLM+LkaVZiKne7WIvT/om8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyoons/ESAA/blob/main/2022_11_21_%EA%B3%BC%EC%A0%9C_%ED%8C%8C%EC%9D%B4%EC%8D%AC_%EB%A8%B8%EC%8B%A0%EB%9F%AC%EB%8B%9D_%EC%99%84%EB%B2%BD%EA%B0%80%EC%9D%B4%EB%93%9C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ch 05. 회귀\n",
        "\n",
        ">**01. 회귀 소개**\n",
        "\n",
        "데이터 값이 평균과 같은 일정한 값으로 돌아가려는 경향을 이용한 기법. 최적의 회귀 계수 찾기.\n",
        "\n",
        "지도학습의 두 가지 유형은 분류와 회귀. 대표적인 선형 회귀 모델은 다음과 같다.\n",
        "* 일반 선형 회귀 : RSS 최소화하도록 회귀 계수 최적화. 규제 적용 안함.\n",
        "* 릿지 : 선형 회귀에 L2규제 추가.\n",
        "* 라쏘 : 선형 회귀에 L1규제 추가.\n",
        "* 엘라스틱넷 : L2, L1 규제 결합한 모델. 피처가 많은 데이터 세트.\n",
        "* 로지스틱 회귀 : 사실 분류에 사용.\n",
        "\n",
        "\n",
        ">**02. 단순 선형 회귀를 통한 회귀 이해**\n",
        "\n",
        "단순 선형 회귀는 독립변수도 종속변수도 하나인 선형 회귀. RSS를 최소로 하는 회귀 계수를 학습을 통해 찾는 것이 머신러닝 기반 회귀의 핵심 사항. RSS는 회귀에서 비용이며 회귀 계수 w로 구성되는 RSS를 비용 함수라고 함. 머신러닝 회귀 알고리즘은 데이터를 계속 학습하며 이 비용 함수가 반환하는 오류 값을 지속해서 감소시키고 최종적으로는 더 이상 감소하지 않는 최소의 오류 값을 구하는 것.\n",
        "\n",
        "\n",
        ">**03. 비용 최소화하기 - 경사 하강법(Gradient Descent) 소개**\n",
        "\n",
        "어떻게 비용 함수가 최소가 되는 w 파라미터를 구할 수 있을까? 경사 하강법. 반복적으로 비용 함수의 반환 값, 즉 예측값과 실제 값이 차이가 작아지는 방향성을 가지고 W 파라미터를 지속해서 보정해 나간다. 어떻게 하면 오류가 작아지는 방향으로 W 값을 보정할 수 있을까? 미분된 1차 함수의 기울기가 감소하지 않는 지점을 비용 함수가 최소인 지점으로 간주하고 이때의 w 반환. R(w)를 w0, w1로 편미분하여 구해야함.\n",
        "\n",
        "파이썬 코드로 구현해보자. y=4x+6을 근사하기 위한 100개의 데이터를 만들고 여기에 경사 하강법을 이용해 회귀 계수 w0, w1을 도출할 것."
      ],
      "metadata": {
        "id": "tyIKURPA-TWo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "qXP5qWe5-MlR",
        "outputId": "61062aa8-4536-4d39-f6b2-385f91f1f342"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fd4978a3b10>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "np.random.seed(0)\n",
        "#y=4x+6을 근사 (w1=4, w0=6). 임의의 값은 노이즈를 위해 만듦.\n",
        "x=2*np.random.rand(100,1)\n",
        "y=6+4*x+np.random.randn(100,1)\n",
        "\n",
        "#x,y 데이터 세트 산점도로 시각화\n",
        "plt.scatter(x,y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "데이터가 무작위로 퍼져 있다. 비용 함수 정의해보자. get_cost() 이용."
      ],
      "metadata": {
        "id": "sV7W91JdBdr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cost(y, y_pred):\n",
        "  N=len(y)\n",
        "  cost=np.sum(np.square(y-y_pred))/N\n",
        "  return cost"
      ],
      "metadata": {
        "id": "auryT0L_BkBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 경사 하강법을 gradient_descent() 함수를 생성해 구현하자. w1, w0을 모두 0으로 초기화 한 뒤, iters 개수만큼 반복하며 w1, w0을 업데이트한다. "
      ],
      "metadata": {
        "id": "5i1JH9otCCk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#w1, w0을 업데이트 할 w1_update, w0_update를 반환.\n",
        "def get_weight_updates(w1, w0, x, y, learning_rate=0.01):\n",
        "  N=len(y)\n",
        "  #먼저 w1_update, w0_update를 각각 w1, w0의 shape과 동일한 크기를 가진 0 값으로 초기화\n",
        "  w1_update=np.zeros_like(w1)\n",
        "  w0_update=np.zeros_like(w0)\n",
        "  #예측 배열 계산하고 예측과 실제 값의 차이 계산\n",
        "  y_pred=np.dot(x, w1.T)+w0\n",
        "  diff=y-y_pred\n",
        "\n",
        "  #w0_update를 dot 행렬 연산으로 구하기 위해 모두 1값을 가진 행렬 생성\n",
        "  w0_factors=np.ones((N,1))\n",
        "  #w1과 w0을 업데이트할 w1_update와 w0_update를 계산\n",
        "  w1_update=-(2/N)*learning_rate*(np.dot(x.T, diff))\n",
        "  w0_update=-(2/N)*learning_rate*(np.dot(w0_factors.T, diff))\n",
        "\n",
        "  return w1_update, w0_update"
      ],
      "metadata": {
        "id": "nU60UsNTCQ8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "get_weight_update를 경사 하강 방식으로 반복적으로 수행하여 w1과 w0를 업데이트 하는 함수를 생성하자."
      ],
      "metadata": {
        "id": "0vIlrFzkDT4r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#입력 인자 iters로 주어진 횟수만큼 반복적으로 w1과 w0를 업데이트 적용함.\n",
        "def gradient_descent_steps(x,y,iters=10000):\n",
        "  #w0, w1을 모두 0으로 초기화\n",
        "  w0=np.zeros((1,1))\n",
        "  w1=np.zeros((1,1))\n",
        "\n",
        "  #인자로 주어진 iters만큼 반복적으로 get_weight_updates() 호출해 w1, w0 업데이트 수행.\n",
        "  for ind in range(iters):\n",
        "    w1_update, w0_update=get_weight_updates(w1, w0, x, y, learning_rate=0.01)\n",
        "    w1=w1-w1_update\n",
        "    w0=w0-w0_update\n",
        "\n",
        "  return w1, w0"
      ],
      "metadata": {
        "id": "4gqR5rMXDbYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 gradient_descent_steps() 호출해 w1, w0을 구현해보자. 최종적으로 예측값과 실제값의 RSS 차이를 계산하는 get_cost() 함수를 생성해 경사 하강법의 예측 오류도 계산해보자."
      ],
      "metadata": {
        "id": "KqWyVEDWEA2c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cost(y, y_pred):\n",
        "  N=len(y)\n",
        "  cost=np.sum(np.square(y-y_pred))/N\n",
        "  return cost\n",
        "\n",
        "w1, w0=gradient_descent_steps(x,y,iters=10000)\n",
        "print('w1:{0:.3f} w0:{1:.3f}'.format(w1[0,0], w0[0,0]))\n",
        "y_pred=w1[0,0]*x+w0\n",
        "print('Gradinet Descent Total Cost:{0:.4f}'.format(get_cost(y, y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SY8aV4XAEM_f",
        "outputId": "fabd64a5-9b24-4362-9e82-c98232d167a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w1:3.968 w0:6.222\n",
            "Gradinet Descent Total Cost:0.9924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "실제와 비슷! 앞에서 구한 y_pred에 기반해 회귀선도 그려보자."
      ],
      "metadata": {
        "id": "VzyqFHMuE05f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x,y)\n",
        "plt.plot(x, y_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "8AJQS3-DE0lx",
        "outputId": "fb7c14e5-2f2a-4d63-d549-2e09d3512dd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd48e254750>]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "회귀선이 잘 만들어졌다. 경사하강법은 모든 학습 데이터에 대해 반복적으로 업데이터하기 때문에 시간이 오래 걸림. 그래서 실전에서는 대부분 확률적 경사하강법 사용. 확률적 경사 하강법을 함수로 구현해보자. 전체 데이터에서 랜덤하게 batch_size만큼 데이터를 추출해 이를 기반으로 계산한다는 차이가 있음."
      ],
      "metadata": {
        "id": "YbCVg4x4E_Ha"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stochastic_gradient_descent_steps(x,y, batch_size=10, iters=10000):\n",
        "  w0=np.zeros((1,1))\n",
        "  w1=np.zeros((1,1))\n",
        "  prev_cost=100000\n",
        "  iter_index=0\n",
        "\n",
        "  for ind in range(iters):\n",
        "    np.random.seed(ind)\n",
        "    #전체 x,y 데이터에서 랜덤하게 batch_size 만큼 데이터 추출해 sample_x, sample_y 지정\n",
        "    stochastic_random_index=np.random.permutation(x.shape[0])\n",
        "    sample_x=x[stochastic_random_index[0:batch_size]]\n",
        "    sample_y=y[stochastic_random_index[0:batch_size]]\n",
        "    #랜덤하게 batch_size만큼 추출된 데이터 기반으로 w1_update, w0_update 계산 후 업데이트\n",
        "    w1_update, w0_update=get_weight_updates(w1, w0, sample_x, sample_y, learning_rate=0.01)\n",
        "    w1=w1-w1_update\n",
        "    w0=w0-w0_update\n",
        "\n",
        "  return w1, w0"
      ],
      "metadata": {
        "id": "pN7CP3P-FS1Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "w1, w0 및 예측 오류 비용을 계산해보자."
      ],
      "metadata": {
        "id": "kPoP7CrwGVe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w1, w0=stochastic_gradient_descent_steps(x,y,iters=10000)\n",
        "print('w1:', round(w1[0,0], 3), 'w0:', round(w0[0,0], 3))\n",
        "y_pred=w1[0,0]*x+w0\n",
        "print('stochastic gradient descent total cost:{0:.4f}'.format(get_cost(y, y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxrY-rcuGZVM",
        "outputId": "5dd88363-d854-4386-c1d1-1c56a7ec1d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w1: 3.988 w0: 6.244\n",
            "stochastic gradient descent total cost:0.9942\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "큰 차이 없음. 큰 데이터 처리 시 확률적 경사 하강법 사용하자. \n",
        "\n",
        "지금까지는 단순 선형 회귀. 피처가 여러개인 경우는? 확장하여 사용.\n",
        "\n",
        "\n",
        ">**05. 다항 회귀와 과(대)적합/과소적합 이해**\n",
        "\n",
        "**다항 회귀 이해**\n",
        "\n",
        "회귀가 독립변수의 단항식이 아닌 2차, 3차 방정식 같은 다항식으로 표현되는 것. 그래도 선형회귀다! 사이킷런은 다항 회귀를 위한 클래스를 제공하지는 않음. 하지만 다항 회귀 역시 선형회귀라서 비선형 함수를 선형 모델에 적용시키는 방법을 사용해 구현.\n",
        "\n",
        "사이킷런의 polynomialFeatures 클래스를 통해 피처를 polynomial(다항식)으로 변환."
      ],
      "metadata": {
        "id": "-9d5AcFXG25N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "import numpy as np\n",
        "\n",
        "#다항식으로 변환한 단항식 생성, [[0,1], [2,3]]의 2*2 행렬 생성\n",
        "x=np.arange(4).reshape(2,2)\n",
        "print('일차 단항식 계수 피처:\\n', x)\n",
        "\n",
        "#degree=2인 2차 다항식으로 변환하기 위해 polynomialfeatures를 이용해 변환\n",
        "poly=PolynomialFeatures(degree=2)\n",
        "poly.fit(x)\n",
        "poly_ftr=poly.transform(x)\n",
        "print('변환된 2차 다항식 계수 피처:\\n', poly_ftr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsvvftWjH4lO",
        "outputId": "f5a31f41-07d4-461f-f122-23c643513fe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "일차 단항식 계수 피처:\n",
            " [[0 1]\n",
            " [2 3]]\n",
            "변환된 2차 다항식 계수 피처:\n",
            " [[1. 0. 1. 0. 0. 1.]\n",
            " [1. 2. 3. 4. 6. 9.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "단항 계수 피처를 2차 다항 계수로 변경함. 이렇게 변환된 피처에 선형 회귀를 적용해 다항 회귀를 구현.\n",
        "\n",
        "3차 다항 회귀 함수를 임의로 설정하고 이의 회귀 계수를 예측할 것."
      ],
      "metadata": {
        "id": "4q4sziX8Ig_5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def polynomial_func(x):\n",
        "  y=1+2*x[:, 0]+3*x[:,0]**2+4*x[:,1]**3\n",
        "  return y\n",
        "\n",
        "x=np.arange(4).reshape(2,2)\n",
        "print('일차 단항식 계수 feature:\\n', x)\n",
        "y=polynomial_func(x)\n",
        "print('삼차 다항식 결정값:\\n', y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk-y1o1uIwYH",
        "outputId": "52a2a843-1f7d-4e9b-d3bd-fd91f7c66674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "일차 단항식 계수 feature:\n",
            " [[0 1]\n",
            " [2 3]]\n",
            "삼차 다항식 결정값:\n",
            " [  5 125]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "#3차 다항식 변환\n",
        "poly_ftr=PolynomialFeatures(degree=3).fit_transform(x)\n",
        "print('3차 다항식 계수 feature:\\n', poly_ftr)\n",
        "\n",
        "#Linear Regression에 3차 다항식 계수 feature와 3차 다항식 결정값으로 학습 후 회귀 계수 확인\n",
        "model=LinearRegression()\n",
        "model.fit(poly_ftr, y)\n",
        "print('Polynomial 회귀 계수\\n', np.round(model.coef_,2))\n",
        "print('Polynomial 회귀 shape :', model.coef_.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bt1Jzd9NJP8_",
        "outputId": "e3cb972a-f33b-4257-a6a9-2e975a627a5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3차 다항식 계수 feature:\n",
            " [[ 1.  0.  1.  0.  0.  1.  0.  0.  0.  1.]\n",
            " [ 1.  2.  3.  4.  6.  9.  8. 12. 18. 27.]]\n",
            "Polynomial 회귀 계수\n",
            " [0.   0.18 0.18 0.36 0.54 0.72 0.72 1.08 1.62 2.34]\n",
            "Polynomial 회귀 shape : (10,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "일차 단항식 계수 피처는 2개였지만 3차 다항식 변환 이후에는 10개로 늘어남. 원래 다항식 계수 값인 [1,2,0,3,0,0,0,0,0,4]와 근사하고 있음.\n",
        "\n",
        "별도로 하는 것보단 사이킷런의 pipeline 객체를 이용해 한번에 다항 회귀를 구현하는 것이 더 명료."
      ],
      "metadata": {
        "id": "0KAL6pUtKOIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "import numpy as np\n",
        "\n",
        "def polynomial_func(x):\n",
        "  y=1 + 2*x[:,0] + 3*x[:,0]**2 + 4*x[:,1]**3\n",
        "  return y\n",
        "\n",
        "#pipeline 객체로 streamline하게 polynomial feature 변환과 linear regression을 연결\n",
        "model=Pipeline([('poly', PolynomialFeatures(degree=3)), ('linear', LinearRegression())])\n",
        "x=np.arange(4).reshape(2,2)\n",
        "y=polynomial_func(x)\n",
        "\n",
        "model=model.fit(x,y)\n",
        "\n",
        "print('Polynomial 회귀 계수\\n', np.round(model.named_steps['linear'].coef_, 2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2xcDEouKiJ5",
        "outputId": "1b396a8d-6786-47c9-9868-b81ea059ab15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Polynomial 회귀 계수\n",
            " [0.   0.18 0.18 0.36 0.54 0.72 0.72 1.08 1.62 2.34]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**다항 회귀를 이용한 과소적합 및 과적합 이해**\n",
        "\n",
        "다항 회귀는 직선적 관계가 아닌 복잡한 다항 관계 모델링 가능. 하지만 차수를 높일수록 학습 데이터에만 너무 맞춘 학습이 이루어져 정작 테스트 데이터 환경에서는 오히려 예측 정확도 떨어진다. =과적합. \n",
        "\n",
        "다항 회귀를 이용한 과소적합과 과적합 문제 예시 보자. 학습 데이터는 30개의 임의의 데이터인 x, 그리고 x의 코사인 값에서 약간의 잡음 변동 값을 더한 target인 y로 구성."
      ],
      "metadata": {
        "id": "__tui_jWLkQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "%matplotlib inline\n",
        "\n",
        "#임의의 값으로 구성된 x값에 대해 코사인 변환 값을 반환.\n",
        "def true_fun(x):\n",
        "  return np.cos(1.5*np.pi*x)\n",
        "\n",
        "#x는 0부터 1까지 30개의 임의의 값을 순서대로 샘플링한 데이터\n",
        "np.random.seed(0)\n",
        "n_samples=30\n",
        "x=np.sort(np.random.rand(n_samples))\n",
        "\n",
        "#y값은 코사인 기반의 true_fun에서 약간의 노이즈 변동 값을 더한 값\n",
        "y=true_fun(x)+np.random.randn(n_samples)*0.1"
      ],
      "metadata": {
        "id": "Gw-FQ64uMEkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 예측 결과를 비교할 다항식 차수를 1,4,15로 변경하며 예측 결과 비교하자.\n",
        "\n",
        "세 가지 그래프가 나온다.\n",
        "Degree 15의 회귀 계수를 살펴보면 매우 크다. 복잡한 다항식을 만족하기 위해 계산된 회귀 계수는 결국 현실과 너무 동떨어짐. 좋은 예측 모델은 지나치게 단순화한 과소적합 모델도, 지나치게 복잡한 과적합 모델도 아닌 균형잡힌 모델이다.\n",
        "\n",
        "**편향-분산 트레이드 오프**\n",
        "\n",
        "고편향과 고분산. 편향과 분산은 한 쪽이 높아지면 한 쪽은 낮아진다. 하지만 편향이나 분산 둘 중 하나가 너무 높으면 전체오류가 높아 예측 성능이 저하된다. 높은 편향/낮은 분산에서 과소적합 되기 쉬우며 높은 분산/낮은 편향에서 과적합 되기 쉽다. 서로 트레이드 오프 이루며 오류 cost 값이 최대로 낮아지는 모델을 구하는 것이 가장 효율적이다.\n"
      ],
      "metadata": {
        "id": "B4XYbSubM4-G"
      }
    }
  ]
}