{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/M8oGVdVdwNUK5CpZLq+y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyoons/ESAA/blob/main/Ch_09_%EC%B6%94%EC%B2%9C%EC%8B%9C%EC%8A%A4%ED%85%9C_%EA%B3%BC%EC%A0%9C1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Ch 09. 추천 시스템**"
      ],
      "metadata": {
        "id": "mYJAi0lAl_rk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**01. 추천 시스템의 개요와 배경**\n",
        "\n",
        "###**추천 시스템의 개요**\n",
        "추천 시스템의 시대. 유튜브, 전자상거래 등. 선택된 콘텐츠와 연관된 추천 콘텐츠가 얼마나 사용자의 관심을 끌고 개인에게 맞춘 콘텐츠를 추천했는지는 그 사이트의 평판을 좌우. 사용자는 해당 사이트를 더 강하게 신뢰하고 더 많은 추천 콘텐츠를 선택한다. 더 많은 데이터가 쌓이며 더욱 정확하고 다양한 결과를 얻을 수 있는 좋은 선순환 시스템 구축. \n",
        "\n",
        "###**온라인 스토어의 필수 요소, 추천 시스템**\n",
        "한정된 시간이라는 제약에서 느끼는 압박감을 타개하는 추천 시스템.\n",
        "- 사용자가 어떤 상품을 구매했는가?\n",
        "- 사용자가 어떤 상품을 둘러보고 장바구니에 넣었는가?\n",
        "- 사용자가 평가한 영화, 제품\n",
        "- 사용자가 스스로 작성한 취향\n",
        "- 사용자가 클릭한 것\n",
        "\n",
        "등의 데이터를 이용해 시스템 구축.\n",
        "\n",
        "###**추천 시스템의 유형**\n",
        "추천 시스템은\n",
        "- 콘텐츠 기반 필터링\n",
        "- 협업 필터링 : 최근접 이웃 협업 필터링, **잠재 요인 협업 필터링**\n",
        "\n",
        "방식으로 나뉜다. 적절한 방식 선택."
      ],
      "metadata": {
        "id": "_cdRVI0sn0mU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**02. 콘텐츠 기반 필터링 추천 시스템**\n",
        ": 사용자가 특정 아이템을 매우 선호하는 경우, 그 아이템과 비슷한 콘텐츠를 가진 다른 아이템을 추천하는 방식.\n",
        "\n",
        "ex. 영화에서 장르, 감독, 배우, 키워드 등이 비슷한 작품 추천."
      ],
      "metadata": {
        "id": "ELIIcoFInw7M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**03. 최근접 이웃 협업 필터링**\n",
        ": 친구들에게 물어보는 것과 비슷하게, 사용자가 아이템에 매긴 평점 정보나 상품 구매 이력과 같은 사용자 행동 양식만을 기반으로 추천을 수행하는 방식.\n",
        "\n",
        "협업 필터링의 주요 목표는 사용자-아이템 평점 매트릭스와 같은 축적된 사용자 행동 데이터를 기반으로 사용자가 아직 평가하지 않은 아이템을 예측 평가 하는 것. 사용자가 평가한 다른 아이템을 기반으로 사용자가 평가하지 않은 아이템의 예측 평가를 도출하는 방식.\n",
        "\n",
        "- 최근접 이웃 방식 = 메모리 협업 필터링\n",
        "- 잠재 요인 방식\n",
        "\n",
        "으로 나뉜다. 두 방식 모두 사용자-아이템 평점 행렬 데이터에만 의지해 추천 수행. 많은 아이템을 열로 가지는 다차원 행렬이며, 사용자가 아이템에 대한 평가를 매기는 경우가 많지 않아 희소 행렬 특성을 가진다. 행이 사용자, 열이 아이템임.\n",
        "\n",
        "최근접 이웃 협업 필터링(메모리 협업 필터링)은\n",
        "- 사용자 기반 : 당신과 비슷한 고객이 다음 상품도 구매\n",
        "- **아이템 기반** : 이 상품을 선택한 고객이 다음 상품도 구매\n",
        "\n",
        "으로 나눌 수 있다.\n",
        "\n",
        "사용자 기반 최근접 이웃 방식은 특정 사용자와 유사한 다른 사용자를 TOP-N으로 선정해 이 TOP-N 사용자가 좋아하는 아이템을 추천하는 방식. 즉, 특정 사용자와 타 사용자 간의 유사도를 측정해 가장 유사도가 높은 TOP-N 사용자를 추출해 그들이 선호하는 아이템을 추천.\n",
        "\n",
        "아이템 기반 최근접 이웃 방식은 '아이템 간의 속성'이 얼마나 비슷한지를 기반으로 추천하는게 아님. 아이템이 갖는 속성과는 상관 없이 사용자들이 그 아이템을 좋아하는지/싫어하는지 평가 척도가 유사한 아이템을 추천하는 기준이 됨. 일반적으로 사용자 기반보다는 아이템 기반 협업이 정확도 더 높다.\n",
        "\n",
        "앞 장의 코사인 유사도는 추천 시스템의 유사도 측정에 가장 많이 적용된다."
      ],
      "metadata": {
        "id": "sQ0G68p-oQMr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**04. 잠재 요인 협업 필터링**\n",
        "\n",
        "###**잠재 요인 협업 필터링의 이해**\n",
        ": 사용자-아이템 평점 매트릭스만을 이용해 그 속에 숨어 있는 잠재 요인을 추출해 추천 예측을 할 수 있게 하는 기법.\n",
        "\n",
        "대규모 다차원 행렬을 SVD와 같은 차원 감소 기법으로 분해하는 과정에서 잠재 요인을 추출 = 행렬 분해.\n",
        "\n",
        "잠재요인을 기반으로 다차원 희소 행렬인 사용자-아이템 행렬 데이터를 저차원 밀집 행렬의 사용자-잠재요인 행렬과 아이템-잠재요인 행렬의 전치 행렬로 분해할 수 있으며 이렇게 분해된 두 행렬의 내적을 통해 새로운 예측 사용자-아이템 평점 행렬을 만들어 사용자가 아직 평점을 부여하지 않은 아이템에 대한 예측 평점을 생성하는 것이 잠재 요인 협력 필터링 알고리즘의 골자. \n",
        "\n",
        "잠재 요인이 정확히 어떤 것인지는 모르지만, 가령 영화 평점 기반의 사용자-아이템 평점 행렬 데이터라면 영화가 가지는 장르별 특성 선호도 등으로 가정할 수 있다. ex. 장르별 선호도와 영화의 장르별 특성 벡터를 서로 곱하기."
      ],
      "metadata": {
        "id": "RawN2IA-quX1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**행렬 분해의 이해**\n",
        "다차원의 매트릭스를 저차원 매트릭스로 분해하는 기법으로 대표적으로 SVD, NMF 등이 있다. M개의 사용자행과 N개의 아이템 열을 가진 평점 행렬 R을 가정. 행렬 분해를 통해 사용자-K 차원 잠재 요인 행렬 P와 K 차원 잠재 요인-아이템 행렬 Q.T로 분해할 수 있다. R 행렬의 u행 사용자와 i열 아이템 위치에 있는 평점 데이터를 r(u, i)라고 하면 r(u, i)=pu*qti 로 유추할 수 있다. 이렇게 사용자가 평가하지 않은 아이템에 대한 평점도 잠재 요인으로 분해된 P 행렬과 Q 행렬을 이용해 예측할 수 있다.\n",
        "\n",
        "R 행렬을 어떻게 P와 Q 행렬로 분해할까? 주로 SVD 방식 이용. 하지만 SVD는 null 이 없는 행렬에서만 적용할 수 있다. 평점이 되지 않은 셀이 있는 R 행렬에서는 사용 불가. 이럴 경우 확률적 경사 하강법이나 ALS 방식으로 SVD 수행."
      ],
      "metadata": {
        "id": "4LQc6yvZABpG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**확률적 경사 하강법을 이용한 행렬 분해**\n",
        ": P와 Q 행렬로 계산된 예측 R 행렬 값이 실제 R 행렬 값과 가장 최소의 오류를 가질 수 있도록 반복적으로 비용 함수를 최적화해 P와 Q 를 유추하는 것.\n",
        "\n",
        "1. P와 Q를 임의의 행렬로 설정\n",
        "2. P와 Q.T를 곱해 예측 R을 계싼하고 실제 R 행렬과의 오류 값을 계산\n",
        "3. 이 오류를 최소화할 수 있도록 P와 Q 행렬을 적절한 값으로 업데이트\n",
        "4. 반복하며 오류 최소화\n",
        "\n",
        "L2 규제를 반영해 실제 R 행렬 값과 예측 R 행렬 값의 차이를 최소화하는 방향성을 가지고 P 행렬과 Q 행렬에 업데이트 값을 반복적으로 수행하면서 최적화된 예측 R 행렬을 구하는 방식이 SGD 기반의 행렬 분해.\n",
        "\n",
        "SGD를 파이썬으로 구현해보자."
      ],
      "metadata": {
        "id": "4n5wWMiEBY8w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#원본 행렬 R 생성, 분해 행렬 P와 Q 초기화, 잠재요인 차원 K는 3으로 설정.\n",
        "R=np.array([[4, np.NaN, np.NaN, 2, np.NaN],\n",
        "            [np.NaN, 5, np.NaN, 3, 1],\n",
        "            [np.NaN, np.NaN, 3, 4, 4],\n",
        "            [5,2,1,2,np.NaN]])\n",
        "num_users, num_items=R.shape\n",
        "K=3\n",
        "\n",
        "#P와 Q의 행렬 크기를 지정하고 정규 분포를 가진 임의의 값으로 입력\n",
        "np.random.seed(1)\n",
        "P=np.random.normal(scale=1./K, size=(num_users, K))\n",
        "Q=np.random.normal(scale=1./K, size=(num_items, K))"
      ],
      "metadata": {
        "id": "voG6ESYDCTvF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "실제 R 행렬과 예측 행렬의 오차를 구하는 함수 생성"
      ],
      "metadata": {
        "id": "xgnaNZ0QC6Bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def get_rmse(R, P, Q, non_zeros):\n",
        "  error=0\n",
        "  #두개의 분해된 행렬 P와 Q.T의 내적으로 예측 R 행렬 생성\n",
        "  full_pred_matrix=np.dot(P, Q.T)\n",
        "\n",
        "  #실제 R 행렬에서 널이 아닌 값의 위치 인덱스를 추출해 실제 R 행렬롸 예측 행렬의 RMSE 추출\n",
        "  x_non_zero_ind=[non_zero[0] for non_zero in non_zeros]\n",
        "  y_non_zero_ind=[non_zero[1] for non_zero in non_zeros]\n",
        "  R_non_zeros=R[x_non_zero_ind, y_non_zero_ind]\n",
        "  full_pred_matrix_non_zeros=full_pred_matrix[x_non_zero_ind, y_non_zero_ind]\n",
        "  mse=mean_squared_error(R_non_zeros, full_pred_matrix_non_zeros)\n",
        "  rmse=np.sqrt(mse)\n",
        "\n",
        "  return rmse"
      ],
      "metadata": {
        "id": "K2iJTqfnC_Pc"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 SGD 기반으로 행렬 분해 수행하자. 먼저 R에서 null 값을 제외한 데이터의 행렬 인덱스를 추출한다. steps=1000번 반복하며 pu, qi 값으로 업데이트 하며 get_rmse()를 통해 50번 반복할 때마다 오류 값을 출력한다."
      ],
      "metadata": {
        "id": "FWGU-K32D1rN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#R>0인 행과 열의 위치, 값을 non_zeros 리스트에 저장\n",
        "non_zeros=[ (i, j, R[i, j]) for i in range(num_users) for j in range(num_items) if R[i, j]>0]\n",
        "steps=1000\n",
        "learning_rate=0.01\n",
        "r_lambda=0.01\n",
        "\n",
        "#SGD 기법으로 P와 Q 매트릭스를 계속 업데이트\n",
        "for step in range(steps):\n",
        "  for i, j, r in non_zeros:\n",
        "    #실제 값과 예측 값의 차이인 오류 값 구함\n",
        "    eij=r-np.dot(P[i, :], Q[j, :].T)\n",
        "    #Regularization을 반영한 SGD 업데이트 공식 적용\n",
        "    P[i, :]=P[i, :]+learning_rate*(eij*Q[j, :]-r_lambda*P[i, :])\n",
        "    Q[j, :]=Q[j, :]+learning_rate*(eij*P[i, :]-r_lambda*Q[j, :])\n",
        "  rmse=get_rmse(R, P, Q, non_zeros)\n",
        "  if (step%50)==0:\n",
        "    print('### iteration step : ', step, 'rmse : ', rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByLzUgAjrHPZ",
        "outputId": "2d57eb8d-57f9-40ab-bed5-8c3402875694"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### iteration step :  0 rmse :  3.2388050277987723\n",
            "### iteration step :  50 rmse :  0.4876723101369648\n",
            "### iteration step :  100 rmse :  0.1564340384819247\n",
            "### iteration step :  150 rmse :  0.07455141311978046\n",
            "### iteration step :  200 rmse :  0.04325226798579314\n",
            "### iteration step :  250 rmse :  0.029248328780878973\n",
            "### iteration step :  300 rmse :  0.022621116143829466\n",
            "### iteration step :  350 rmse :  0.019493636196525135\n",
            "### iteration step :  400 rmse :  0.018022719092132704\n",
            "### iteration step :  450 rmse :  0.01731968595344266\n",
            "### iteration step :  500 rmse :  0.016973657887570753\n",
            "### iteration step :  550 rmse :  0.016796804595895633\n",
            "### iteration step :  600 rmse :  0.01670132290188466\n",
            "### iteration step :  650 rmse :  0.01664473691247669\n",
            "### iteration step :  700 rmse :  0.016605910068210026\n",
            "### iteration step :  750 rmse :  0.016574200475705\n",
            "### iteration step :  800 rmse :  0.01654431582921597\n",
            "### iteration step :  850 rmse :  0.01651375177473524\n",
            "### iteration step :  900 rmse :  0.01648146573819501\n",
            "### iteration step :  950 rmse :  0.016447171683479155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제 분해된 P와 Q 함수를 P*Q.T로 예측 행렬을 만들어 출력하자."
      ],
      "metadata": {
        "id": "xoGg8WCPsifl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_matrix=np.dot(P, Q.T)\n",
        "print('예측 행렬:\\n', np.round(pred_matrix, 3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GlNTQf1spaR",
        "outputId": "4fece1b3-6eeb-49da-80f8-54ff7972f610"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 행렬:\n",
            " [[3.991 0.897 1.306 2.002 1.663]\n",
            " [6.696 4.978 0.979 2.981 1.003]\n",
            " [6.677 0.391 2.987 3.977 3.986]\n",
            " [4.968 2.005 1.006 2.017 1.14 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "R"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raaz5RFjsyCy",
        "outputId": "46a86c2a-b708-474f-dd54-d5a65ba94b77"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4., nan, nan,  2., nan],\n",
              "       [nan,  5., nan,  3.,  1.],\n",
              "       [nan, nan,  3.,  4.,  4.],\n",
              "       [ 5.,  2.,  1.,  2., nan]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "원본 행렬과 비교해보니 null이 아니면 큰 차이가 나지는 않고, null인 값은 새로운 값으로 채워졌다."
      ],
      "metadata": {
        "id": "eibpFw92sz4f"
      }
    }
  ]
}
