{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LPk54ZiC4nob",
        "m3QUXgwZ4pt1",
        "r2-pDHz88t3-"
      ],
      "authorship_tag": "ABX9TyPsq25+fLas0tVL8KYJM549",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyoons/ESAA/blob/main/%EC%8A%A4%ED%84%B0%EB%94%94_1%EC%B0%A8_%EB%B6%84%EB%A5%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#분류"
      ],
      "metadata": {
        "id": "HUBNJ2qV4OJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##01. 분류의 개요\n",
        "배깅 - 랜덤 포레스트\n",
        "\n",
        "부스팅 - 그래디언트 부스팅, XGB, LGBM"
      ],
      "metadata": {
        "id": "sw1xM_qo9Hq2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##02. 결정 트리\n",
        "\n",
        "쉽고 직관적, 사전 가공 영향도가 크지 않음\n",
        "\n",
        "하지만 과적합으로 성능 떨어짐. 트리의 크기를 사전에 제한하는 튜닝 필요.\n",
        "\n",
        "DecisionTreeClassifier의 파라미터\n",
        "- min_samples_split : 노드 분할하기 위한 최소한의 샘플 데이터 수, 과적합 제어\n",
        "- min_samples_leaf : 말단 노드가 되기 위한 최소한의 샘플 데이터 수\n",
        "- max_features : 최적의 분할을 위해 고려할 최대 피처 수, 디폴트는 모든 피처\n",
        "- max_depth\n",
        "- max_leaf_nodes"
      ],
      "metadata": {
        "id": "1GNFX8--4dFL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###결정 트리 실습 - 사용자 행동 인식 데이터 세트\n",
        "피처명 보니 인체의 움직임과 관련된 속성의 평균/표준편차가 x,y,z축 값으로 되어 있음."
      ],
      "metadata": {
        "id": "Mv37j5zI9B6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#중복되는 피처명을 _1, _2 처리하는 함수 생성\n",
        "def get_new_feature_name_df(old_feature_name_df):\n",
        "  feature_dup_df=pd.DataFrame(data=old_feature_name_df.groupby('column_name').cumcount(), columns=['dup_cnt'])\n",
        "  feature_dup_df=feature_dup_df.reset_index()\n",
        "  new_feature_name_df=pd.merge(old_feature_name_df.reset_index(), feature_dup_df, how='outer')\n",
        "  new_feature_name_df['column_name']=new_feature_name_df[['column_name', 'dup_cnt']].apply(lambda x : x[0]+'_'+str(x[1]) if x[1]>0 else x[0], axis=1)\n",
        "  new_feature_name_df=new_feature_name_df.drop(['index'], axis=1)\n",
        "  return new_feature_name_df"
      ],
      "metadata": {
        "id": "DQ-zfI7p6IOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#get_humans_dataset() 정의\n",
        "import pandas as pd\n",
        "\n",
        "def get_human_dataset():\n",
        "  feature_name_df=pd.read_csv('features.txt', sep='\\s+', header=None, names=['column_index', 'column_name'])\n",
        "  new_feature_name_df=get_new_feature_name_df(feature_name_df)\n",
        "  feature_name=new_feature_name_df.iloc[:,1].values.tolist()\n",
        "  X_train=pd.read_csv('X_train.txt', sep='\\s+', names=feature_name)\n",
        "  X_test=pd.read_csv('X_test.txt', sep='\\s+', names=feature_name)\n",
        "  y_train=pd.read_csv('y_train.txt', sep='\\s+', header=None, names=['action'])\n",
        "  y_test=pd.read_csv('y_test.txt', sep='\\s+', header=None, names=['action'])\n",
        "  return X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train, X_test, y_train, y_test=get_human_dataset()"
      ],
      "metadata": {
        "id": "D8acsgQN9Wpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#피처가 모두 숫자형이라 별도의 카테고리 인코딩은 필요 없다.\n",
        "\n",
        "#동작 예측 분류 수행해보자.\n",
        "#먼저 하이퍼 파라미터는 모두 디폴트로 수행하고, 이때의 하이퍼 파라미터 값을 추출해보자.\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "dt_clf=DecisionTreeClassifier(random_state=156)\n",
        "dt_clf.fit(X_train, y_train)\n",
        "pred=dt_clf.predict(X_test)\n",
        "accuracy=accuracy_score(y_test, pred)\n",
        "print('결정 트리 예측 정확도: {0:.4f}'.format(accuracy))\n",
        "\n",
        "#하이퍼 파라미터 추출\n",
        "print('결정 트리의 기본 하이퍼 파라미터:\\n', dt_clf.get_params())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDGaeHef-pTF",
        "outputId": "b06598c1-ccaf-4712-a033-da233f340e80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "결정 트리 예측 정확도: 0.8548\n",
            "결정 트리의 기본 하이퍼 파라미터:\n",
            " {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'random_state': 156, 'splitter': 'best'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#트리 깊이가 주는 영향을 보자. max_depth.\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params={'max_depth':[6,8,10,12,16,20,24]}\n",
        "grid_cv=GridSearchCV(dt_clf, param_grid=params, scoring='accuracy', cv=5, verbose=1)\n",
        "grid_cv.fit(X_train, y_train)\n",
        "print('GridSearchCV 최고 평균 정확도 수치: {0:.4f}'.format(grid_cv.best_score_))\n",
        "print('GridSearchCV 최적 하이퍼 파라미터:', grid_cv.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-eo2oLY_glW",
        "outputId": "e361059f-5d46-4f4d-c372-a88191588e13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 7 candidates, totalling 35 fits\n",
            "GridSearchCV 최고 평균 정확도 수치: 0.8513\n",
            "GridSearchCV 최적 하이퍼 파라미터: {'max_depth': 16}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 트리 깊이가 주는 영향 : 깊어진 트리는 학습 데이터 세트에는 올바른 예측 결과를 가져오나, 검증 데이터 세트에는 과적합으로 성능 저하 유발"
      ],
      "metadata": {
        "id": "ZgK_sR9GAjzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#이제는 max_depth와 min_samples_split을 같이 변경하며 정확도 성능 튜닝\n",
        "params={'max_depth':[8,12,16,20], 'min_samples_split':[16,24]}\n",
        "\n",
        "grid_cv=GridSearchCV(dt_clf, param_grid=params, scoring='accuracy', cv=5, verbose=1)\n",
        "grid_cv.fit(X_train, y_train)\n",
        "print('GridSearchCV 최고 평균 정확도 수치: {0:.4f}'.format(grid_cv.best_score_))\n",
        "print('GridSearchCV 최적 하이퍼 파라미터:', grid_cv.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8WKAVL5A_Fa",
        "outputId": "953ae2dd-a3a4-433f-8e42-9bf26b29dc67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "GridSearchCV 최고 평균 정확도 수치: 0.8549\n",
            "GridSearchCV 최적 하이퍼 파라미터: {'max_depth': 8, 'min_samples_split': 16}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 디폴트일 때 보다 max_depth와 min_samples_split 하이퍼 파라미터 최적화를 통해 성능 향상 가능"
      ],
      "metadata": {
        "id": "rr2YZywLCCqB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##03. 앙상블 학습\n",
        "- 보팅 : 투표를 통해, 일반적으로 서로 다른 알고리즘 결합\n",
        "- 배깅 : 투표를 통해, 같은 분류기지만 데이터 샘플링 다른 학습, 랜덤포레스트\n",
        "- 부스팅 : 여러개 분류기가 순차적 학습, 가중치 부여\n",
        "\n",
        "-\n",
        "\n",
        "- 하드 보팅 : 다수결\n",
        "- 소프트 보팅 : 모두 더해 평균, 일반적!"
      ],
      "metadata": {
        "id": "_3ZTQ0274hLj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##04. 랜덤 포레스트\n",
        "배깅이지만 개별 트리가 학습하는 데이터를 일부가 중첩되게 샘플링함 = 부트스트래핑\n",
        "\n",
        "단점 : 하이퍼 파라미터 많고, 튜닝 시간이 많이 소모된다는 것"
      ],
      "metadata": {
        "id": "rv-lQfDu4jah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###랜덤 포레스트 실습 - 사용자 행동 인식 데이터 세트"
      ],
      "metadata": {
        "id": "umdyDr_088yK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "X_train, X_test, y_train, y_test=get_human_dataset()\n",
        "\n",
        "rf_clf=RandomForestClassifier(random_state=0)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "pred=rf_clf.predict(X_test)\n",
        "accuracy=accuracy_score(y_test, pred)\n",
        "print('랜덤 포레스트 정확도: {0:.4f}'.format(accuracy))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nB8IYm76DpL8",
        "outputId": "a9b6464f-1d71-4597-bade-89510bb7155c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "랜덤 포레스트 정확도: 0.9253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 결정 트리보다 확실히 좋다!"
      ],
      "metadata": {
        "id": "jgJsM_sJEUAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#랜덤 포레스트의 하이퍼 파라미터 튜닝 진행해보자\n",
        "#시간 절약 위해 n_estimators=100, cv=2로 먼저 진행\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params={'n_estimators':[100], 'max_depth':[6,8,10,12], 'min_samples_leaf':[8,12,18], 'min_samples_split':[8,16,20]}\n",
        "\n",
        "rf_clf=RandomForestClassifier(random_state=0, n_jobs=-1)\n",
        "grid_cv=GridSearchCV(rf_clf, param_grid=params, cv=2, n_jobs=-1)\n",
        "grid_cv.fit(X_train, y_train)\n",
        "\n",
        "print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
        "print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COgJvI6DEXMx",
        "outputId": "243a198f-d2f2-43b6-f07d-f1cc9427660d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최적 하이퍼 파라미터:\n",
            " {'max_depth': 10, 'min_samples_leaf': 8, 'min_samples_split': 8, 'n_estimators': 100}\n",
            "최고 예측 정확도: 0.9180\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#n_estimators 높이고 최적화 하이퍼 파라미터로 적용해보자\n",
        "rf_clf1=RandomForestClassifier(n_estimators=300, max_depth=10, min_samples_leaf=8, min_samples_split=8, random_state=0)\n",
        "rf_clf1.fit(X_train, y_train)\n",
        "pred=rf_clf1.predict(X_test)\n",
        "print('예측 정확도: {0:.4f}'.format(accuracy_score(y_test, pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0a2716ifFlqT",
        "outputId": "cf0c8aa4-8f06-420e-9dd8-176ac12999ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측 정확도: 0.9165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##05. GBM\n",
        "\n",
        "###GBM 실습 - 사용자 행동 인식 데이터 세트"
      ],
      "metadata": {
        "id": "-ZER7Waa4lHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from sklearn.ensemble import GradientBoostingClassifier\n",
        "#import time\n",
        "#import warnings\n",
        "#warnings.filterwarnings('ignore')\n",
        "\n",
        "#X_train,X_test, y_train, y_test=get_human_dataset()\n",
        "\n",
        "#GBM 사용 시 수행시간이 얼마나 걸리는지도 보자\n",
        "#start_time=time.time()\n",
        "\n",
        "#gb_clf=GradientBoostingClassifier(random_state=0)\n",
        "#gb_clf.fit(X_train, y_train)\n",
        "#gb_pred=gb_clf.predict(X_test)\n",
        "#gb_accuracy=accuracy_score(y_test, gb_pred)\n",
        "\n",
        "#print('GBM 정확도: {0:.4f}'.format(gb_accuracy))\n",
        "#print('GBM 수행 시간: {0:.1f}초'.format(time.time()-start_time()))"
      ],
      "metadata": {
        "id": "z_bRgok4Habl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 시간이 너무 오래 걸려 # 처리.\n",
        "- 교재에 따르면 랜덤 포레스트보다 조금 나은 성능! 일반적으로는 GBM이 랜덤 포레스트보다 낫다.\n",
        "- 그러나 수행 시간, 하이퍼 파라미터 튜닝 노력이라는 단점... 특히 수행시간이 오래걸림."
      ],
      "metadata": {
        "id": "yEmmepeoIYnO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#하이퍼 파라미터 최적화해보자.\n",
        "\n",
        "#from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "#parmas={'n_estimatiors':[100,500], 'learning_rate':[0.05, 0.1]}\n",
        "\n",
        "#grid_cv=GridSearchCV(gb_clf, param_grid=params, cv=2, verbose=1)\n",
        "#grid_cv.fit(X_train, y_train)\n",
        "#print('최적 하이퍼 파라미터:\\n', grid_cv.best_params_)\n",
        "#print('최고 예측 정확도: {0:.4f}'.format(grid_cv.best_score_))"
      ],
      "metadata": {
        "id": "mx0oIb2MJTXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 수행 시간이 너무 오래 걸려 우선 # 처리\n",
        "- 교재에 따르면 learning_rate=0.05, n_estimators=500일 때 정확도가 90.1%로 최고.\n",
        "- GBM은 확실히 성능은 좋지만 시간이 문제이다."
      ],
      "metadata": {
        "id": "DnrzvOL5J77E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##06. XGBoost\n",
        "\n",
        "앞에서 봤듯 GBM은 시간이 너무 오래 걸림. 따라서 GBM 기반의 알고리즘들이 많이 만들어지고 있는데 그 중 각광 받는 두 가지 패키지가 XGB와 LGBM.\n",
        "\n",
        "특히 XGB는 GBM의 느린 수행 시간과 과적합 규제 부재 등의 문제를 해결했다.\n",
        "\n",
        "초기의 독자적 XGBoost 기반의 XGB는 파이썬 래퍼 XGB 모듈, 사이킷런과 연동되는 모듈은 사이킷런 래퍼 XGB 모듈이라고 지칭. "
      ],
      "metadata": {
        "id": "LPk54ZiC4nob"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###XGB 실습 - 위스콘신 유방암 예측"
      ],
      "metadata": {
        "id": "iK-GUI-K8373"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb #이게 사이킷런 아니고 파이썬 래퍼 XGB 방식\n",
        "from xgboost import plot_importance #xgboost 패키지는 피처 중요도 시각화해주는 모듈도 제공한다!\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "dataset=load_breast_cancer()\n",
        "X_features=dataset.data\n",
        "y_label=dataset.target\n",
        "\n",
        "cancer_df=pd.DataFrame(data=X_features, columns=dataset.feature_names)\n",
        "cancer_df['target']=y_label"
      ],
      "metadata": {
        "id": "0Cy-XeeqytY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 기본적으로 살펴보기에 악성과 양성이 아주 비대칭적이지는 않은 것 같다."
      ],
      "metadata": {
        "id": "X3uLnBHWzbrT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test=train_test_split(X_features, y_label, test_size=0.2, random_state=156)"
      ],
      "metadata": {
        "id": "-rPE4Qb2zheI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 여기서 파이썬 래퍼 XGB가 사이킷런과 다른 점은 학습용과 테스트용 데이터 세트를 위해 별도의 객체인 DMatrix를 생성한다는 것. 사이킷런을 주로 사용할 예정이라 자세히 하지는 않겠음. dtrain과 dtest를 지정하고 하이퍼 파라미터를 설정하여 학습을 수행하면 된다. 교재에서 파이썬 래퍼 XGB의 하이퍼 파라미터로 설정한 것은 max_depth=3, eta=0.1, objective=binary:logistic, eval_metric=logloss, early_stoppings=100. 최적 파라미터는 cv() API로 제공한다. \n",
        "- 참고로 **early_stopping_rounds를 설정하기 위해선 반드시 eval_set과 eval_metric이 함께 설정**되어야 한다.\n",
        "- 교재에 따르면 이렇게 학습했을 경우 파이썬 래퍼 XGB의 정확도는 약 0.9737\n",
        "- 사이킷런으로 넘어가면, 파이썬 래퍼 XGB에서 사용하던 하이퍼 파라미터 몇 개의 이름이 변경된다. eta- > learning_rate, sub_sample -> subsample, lambda -> reg_lambda, alpha -> reg_alpha"
      ],
      "metadata": {
        "id": "ftkO9evxz23B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#사이킷런 래퍼 XGB로 계속해보자.\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb=XGBClassifier(n_estimators=400, learning_rate=0.1, max_depth=3)\n",
        "xgb.fit(X_train, y_train)\n",
        "preds=xgb.predict(X_test)\n",
        "preds_proba=xgb.predict_proba(X_test)[:,1]"
      ],
      "metadata": {
        "id": "L1XCoJ-Z13nq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- get_clf_eval(y_test, preds, pred_proba)로 보면 정확도는 0.9737 즉, 파이썬 래퍼 XGB와 동일한 결과이다. "
      ],
      "metadata": {
        "id": "f2zBKlbw3A4B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#사이킷런에서도 조기 중단 실행 가능\n",
        "xgb=XGBClassifier(n_estimators=400, learning_rate=0.1, max_depth=3)\n",
        "evals=[(X_test, y_test)] #원래 이렇게 하면 안됨! test는 알려지지 않은 데이터임을 유의\n",
        "xgb.fit(X_train, y_train, early_stopping_rounds=100, eval_metric='logloss', eval_set=evals, verbose=True)\n",
        "preds=xgb.predict(X_test)\n",
        "pred_proba=xgb.predict_proba(X_test)[:,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZQyeZXMH38dG",
        "outputId": "17201132-42f0-41b7-fc82-13e5e0167fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-logloss:0.61352\n",
            "Will train until validation_0-logloss hasn't improved in 100 rounds.\n",
            "[1]\tvalidation_0-logloss:0.547842\n",
            "[2]\tvalidation_0-logloss:0.494247\n",
            "[3]\tvalidation_0-logloss:0.447986\n",
            "[4]\tvalidation_0-logloss:0.409109\n",
            "[5]\tvalidation_0-logloss:0.374977\n",
            "[6]\tvalidation_0-logloss:0.345714\n",
            "[7]\tvalidation_0-logloss:0.320529\n",
            "[8]\tvalidation_0-logloss:0.29721\n",
            "[9]\tvalidation_0-logloss:0.277991\n",
            "[10]\tvalidation_0-logloss:0.260302\n",
            "[11]\tvalidation_0-logloss:0.246037\n",
            "[12]\tvalidation_0-logloss:0.231556\n",
            "[13]\tvalidation_0-logloss:0.22005\n",
            "[14]\tvalidation_0-logloss:0.208572\n",
            "[15]\tvalidation_0-logloss:0.199993\n",
            "[16]\tvalidation_0-logloss:0.190118\n",
            "[17]\tvalidation_0-logloss:0.181818\n",
            "[18]\tvalidation_0-logloss:0.174729\n",
            "[19]\tvalidation_0-logloss:0.167657\n",
            "[20]\tvalidation_0-logloss:0.158202\n",
            "[21]\tvalidation_0-logloss:0.154725\n",
            "[22]\tvalidation_0-logloss:0.148947\n",
            "[23]\tvalidation_0-logloss:0.143308\n",
            "[24]\tvalidation_0-logloss:0.136344\n",
            "[25]\tvalidation_0-logloss:0.132778\n",
            "[26]\tvalidation_0-logloss:0.127912\n",
            "[27]\tvalidation_0-logloss:0.125263\n",
            "[28]\tvalidation_0-logloss:0.119978\n",
            "[29]\tvalidation_0-logloss:0.116412\n",
            "[30]\tvalidation_0-logloss:0.114502\n",
            "[31]\tvalidation_0-logloss:0.112572\n",
            "[32]\tvalidation_0-logloss:0.11154\n",
            "[33]\tvalidation_0-logloss:0.108681\n",
            "[34]\tvalidation_0-logloss:0.106681\n",
            "[35]\tvalidation_0-logloss:0.104207\n",
            "[36]\tvalidation_0-logloss:0.102962\n",
            "[37]\tvalidation_0-logloss:0.100576\n",
            "[38]\tvalidation_0-logloss:0.098683\n",
            "[39]\tvalidation_0-logloss:0.096444\n",
            "[40]\tvalidation_0-logloss:0.095869\n",
            "[41]\tvalidation_0-logloss:0.094242\n",
            "[42]\tvalidation_0-logloss:0.094715\n",
            "[43]\tvalidation_0-logloss:0.094272\n",
            "[44]\tvalidation_0-logloss:0.093894\n",
            "[45]\tvalidation_0-logloss:0.094184\n",
            "[46]\tvalidation_0-logloss:0.09402\n",
            "[47]\tvalidation_0-logloss:0.09236\n",
            "[48]\tvalidation_0-logloss:0.093012\n",
            "[49]\tvalidation_0-logloss:0.091272\n",
            "[50]\tvalidation_0-logloss:0.090051\n",
            "[51]\tvalidation_0-logloss:0.089605\n",
            "[52]\tvalidation_0-logloss:0.089577\n",
            "[53]\tvalidation_0-logloss:0.090703\n",
            "[54]\tvalidation_0-logloss:0.089579\n",
            "[55]\tvalidation_0-logloss:0.090357\n",
            "[56]\tvalidation_0-logloss:0.091587\n",
            "[57]\tvalidation_0-logloss:0.091527\n",
            "[58]\tvalidation_0-logloss:0.091986\n",
            "[59]\tvalidation_0-logloss:0.091951\n",
            "[60]\tvalidation_0-logloss:0.091939\n",
            "[61]\tvalidation_0-logloss:0.091461\n",
            "[62]\tvalidation_0-logloss:0.090311\n",
            "[63]\tvalidation_0-logloss:0.089407\n",
            "[64]\tvalidation_0-logloss:0.089719\n",
            "[65]\tvalidation_0-logloss:0.089743\n",
            "[66]\tvalidation_0-logloss:0.089622\n",
            "[67]\tvalidation_0-logloss:0.088734\n",
            "[68]\tvalidation_0-logloss:0.088621\n",
            "[69]\tvalidation_0-logloss:0.089739\n",
            "[70]\tvalidation_0-logloss:0.089981\n",
            "[71]\tvalidation_0-logloss:0.089782\n",
            "[72]\tvalidation_0-logloss:0.089584\n",
            "[73]\tvalidation_0-logloss:0.089533\n",
            "[74]\tvalidation_0-logloss:0.088748\n",
            "[75]\tvalidation_0-logloss:0.088597\n",
            "[76]\tvalidation_0-logloss:0.08812\n",
            "[77]\tvalidation_0-logloss:0.088396\n",
            "[78]\tvalidation_0-logloss:0.088736\n",
            "[79]\tvalidation_0-logloss:0.088153\n",
            "[80]\tvalidation_0-logloss:0.087577\n",
            "[81]\tvalidation_0-logloss:0.087412\n",
            "[82]\tvalidation_0-logloss:0.08849\n",
            "[83]\tvalidation_0-logloss:0.088575\n",
            "[84]\tvalidation_0-logloss:0.08807\n",
            "[85]\tvalidation_0-logloss:0.087641\n",
            "[86]\tvalidation_0-logloss:0.087416\n",
            "[87]\tvalidation_0-logloss:0.087611\n",
            "[88]\tvalidation_0-logloss:0.087065\n",
            "[89]\tvalidation_0-logloss:0.08727\n",
            "[90]\tvalidation_0-logloss:0.087161\n",
            "[91]\tvalidation_0-logloss:0.086962\n",
            "[92]\tvalidation_0-logloss:0.087166\n",
            "[93]\tvalidation_0-logloss:0.087067\n",
            "[94]\tvalidation_0-logloss:0.086592\n",
            "[95]\tvalidation_0-logloss:0.086116\n",
            "[96]\tvalidation_0-logloss:0.087139\n",
            "[97]\tvalidation_0-logloss:0.086768\n",
            "[98]\tvalidation_0-logloss:0.086694\n",
            "[99]\tvalidation_0-logloss:0.086547\n",
            "[100]\tvalidation_0-logloss:0.086498\n",
            "[101]\tvalidation_0-logloss:0.08641\n",
            "[102]\tvalidation_0-logloss:0.086288\n",
            "[103]\tvalidation_0-logloss:0.086258\n",
            "[104]\tvalidation_0-logloss:0.086835\n",
            "[105]\tvalidation_0-logloss:0.086767\n",
            "[106]\tvalidation_0-logloss:0.087321\n",
            "[107]\tvalidation_0-logloss:0.087304\n",
            "[108]\tvalidation_0-logloss:0.08728\n",
            "[109]\tvalidation_0-logloss:0.087298\n",
            "[110]\tvalidation_0-logloss:0.087289\n",
            "[111]\tvalidation_0-logloss:0.088002\n",
            "[112]\tvalidation_0-logloss:0.087936\n",
            "[113]\tvalidation_0-logloss:0.087843\n",
            "[114]\tvalidation_0-logloss:0.088066\n",
            "[115]\tvalidation_0-logloss:0.087649\n",
            "[116]\tvalidation_0-logloss:0.087298\n",
            "[117]\tvalidation_0-logloss:0.087799\n",
            "[118]\tvalidation_0-logloss:0.087751\n",
            "[119]\tvalidation_0-logloss:0.08768\n",
            "[120]\tvalidation_0-logloss:0.087626\n",
            "[121]\tvalidation_0-logloss:0.08757\n",
            "[122]\tvalidation_0-logloss:0.087547\n",
            "[123]\tvalidation_0-logloss:0.087156\n",
            "[124]\tvalidation_0-logloss:0.08767\n",
            "[125]\tvalidation_0-logloss:0.087737\n",
            "[126]\tvalidation_0-logloss:0.088275\n",
            "[127]\tvalidation_0-logloss:0.088309\n",
            "[128]\tvalidation_0-logloss:0.088266\n",
            "[129]\tvalidation_0-logloss:0.087886\n",
            "[130]\tvalidation_0-logloss:0.088861\n",
            "[131]\tvalidation_0-logloss:0.088675\n",
            "[132]\tvalidation_0-logloss:0.088743\n",
            "[133]\tvalidation_0-logloss:0.089218\n",
            "[134]\tvalidation_0-logloss:0.089179\n",
            "[135]\tvalidation_0-logloss:0.088821\n",
            "[136]\tvalidation_0-logloss:0.088512\n",
            "[137]\tvalidation_0-logloss:0.08848\n",
            "[138]\tvalidation_0-logloss:0.088386\n",
            "[139]\tvalidation_0-logloss:0.089145\n",
            "[140]\tvalidation_0-logloss:0.08911\n",
            "[141]\tvalidation_0-logloss:0.088765\n",
            "[142]\tvalidation_0-logloss:0.088678\n",
            "[143]\tvalidation_0-logloss:0.088389\n",
            "[144]\tvalidation_0-logloss:0.089271\n",
            "[145]\tvalidation_0-logloss:0.089238\n",
            "[146]\tvalidation_0-logloss:0.089139\n",
            "[147]\tvalidation_0-logloss:0.088907\n",
            "[148]\tvalidation_0-logloss:0.089416\n",
            "[149]\tvalidation_0-logloss:0.089388\n",
            "[150]\tvalidation_0-logloss:0.089108\n",
            "[151]\tvalidation_0-logloss:0.088735\n",
            "[152]\tvalidation_0-logloss:0.088717\n",
            "[153]\tvalidation_0-logloss:0.088484\n",
            "[154]\tvalidation_0-logloss:0.088471\n",
            "[155]\tvalidation_0-logloss:0.088545\n",
            "[156]\tvalidation_0-logloss:0.088521\n",
            "[157]\tvalidation_0-logloss:0.088547\n",
            "[158]\tvalidation_0-logloss:0.088275\n",
            "[159]\tvalidation_0-logloss:0.0883\n",
            "[160]\tvalidation_0-logloss:0.08828\n",
            "[161]\tvalidation_0-logloss:0.088013\n",
            "[162]\tvalidation_0-logloss:0.087758\n",
            "[163]\tvalidation_0-logloss:0.087784\n",
            "[164]\tvalidation_0-logloss:0.087777\n",
            "[165]\tvalidation_0-logloss:0.087517\n",
            "[166]\tvalidation_0-logloss:0.087542\n",
            "[167]\tvalidation_0-logloss:0.087642\n",
            "[168]\tvalidation_0-logloss:0.08739\n",
            "[169]\tvalidation_0-logloss:0.087377\n",
            "[170]\tvalidation_0-logloss:0.087298\n",
            "[171]\tvalidation_0-logloss:0.087368\n",
            "[172]\tvalidation_0-logloss:0.087395\n",
            "[173]\tvalidation_0-logloss:0.087385\n",
            "[174]\tvalidation_0-logloss:0.087132\n",
            "[175]\tvalidation_0-logloss:0.087159\n",
            "[176]\tvalidation_0-logloss:0.086955\n",
            "[177]\tvalidation_0-logloss:0.087053\n",
            "[178]\tvalidation_0-logloss:0.08697\n",
            "[179]\tvalidation_0-logloss:0.086973\n",
            "[180]\tvalidation_0-logloss:0.087038\n",
            "[181]\tvalidation_0-logloss:0.086799\n",
            "[182]\tvalidation_0-logloss:0.086826\n",
            "[183]\tvalidation_0-logloss:0.086582\n",
            "[184]\tvalidation_0-logloss:0.086588\n",
            "[185]\tvalidation_0-logloss:0.086614\n",
            "[186]\tvalidation_0-logloss:0.086372\n",
            "[187]\tvalidation_0-logloss:0.086369\n",
            "[188]\tvalidation_0-logloss:0.086297\n",
            "[189]\tvalidation_0-logloss:0.086104\n",
            "[190]\tvalidation_0-logloss:0.086023\n",
            "[191]\tvalidation_0-logloss:0.08605\n",
            "[192]\tvalidation_0-logloss:0.086149\n",
            "[193]\tvalidation_0-logloss:0.085916\n",
            "[194]\tvalidation_0-logloss:0.085915\n",
            "[195]\tvalidation_0-logloss:0.085984\n",
            "[196]\tvalidation_0-logloss:0.086012\n",
            "[197]\tvalidation_0-logloss:0.085922\n",
            "[198]\tvalidation_0-logloss:0.085853\n",
            "[199]\tvalidation_0-logloss:0.085874\n",
            "[200]\tvalidation_0-logloss:0.085888\n",
            "[201]\tvalidation_0-logloss:0.08595\n",
            "[202]\tvalidation_0-logloss:0.08573\n",
            "[203]\tvalidation_0-logloss:0.08573\n",
            "[204]\tvalidation_0-logloss:0.085753\n",
            "[205]\tvalidation_0-logloss:0.085821\n",
            "[206]\tvalidation_0-logloss:0.08584\n",
            "[207]\tvalidation_0-logloss:0.085776\n",
            "[208]\tvalidation_0-logloss:0.085686\n",
            "[209]\tvalidation_0-logloss:0.08571\n",
            "[210]\tvalidation_0-logloss:0.085806\n",
            "[211]\tvalidation_0-logloss:0.085593\n",
            "[212]\tvalidation_0-logloss:0.085801\n",
            "[213]\tvalidation_0-logloss:0.085806\n",
            "[214]\tvalidation_0-logloss:0.085744\n",
            "[215]\tvalidation_0-logloss:0.085658\n",
            "[216]\tvalidation_0-logloss:0.085843\n",
            "[217]\tvalidation_0-logloss:0.085632\n",
            "[218]\tvalidation_0-logloss:0.085726\n",
            "[219]\tvalidation_0-logloss:0.085783\n",
            "[220]\tvalidation_0-logloss:0.085791\n",
            "[221]\tvalidation_0-logloss:0.085817\n",
            "[222]\tvalidation_0-logloss:0.085757\n",
            "[223]\tvalidation_0-logloss:0.085674\n",
            "[224]\tvalidation_0-logloss:0.08586\n",
            "[225]\tvalidation_0-logloss:0.085871\n",
            "[226]\tvalidation_0-logloss:0.085927\n",
            "[227]\tvalidation_0-logloss:0.085954\n",
            "[228]\tvalidation_0-logloss:0.085874\n",
            "[229]\tvalidation_0-logloss:0.086057\n",
            "[230]\tvalidation_0-logloss:0.086002\n",
            "[231]\tvalidation_0-logloss:0.085922\n",
            "[232]\tvalidation_0-logloss:0.086102\n",
            "[233]\tvalidation_0-logloss:0.086115\n",
            "[234]\tvalidation_0-logloss:0.086169\n",
            "[235]\tvalidation_0-logloss:0.086263\n",
            "[236]\tvalidation_0-logloss:0.086292\n",
            "[237]\tvalidation_0-logloss:0.086217\n",
            "[238]\tvalidation_0-logloss:0.086395\n",
            "[239]\tvalidation_0-logloss:0.086342\n",
            "[240]\tvalidation_0-logloss:0.08618\n",
            "[241]\tvalidation_0-logloss:0.086195\n",
            "[242]\tvalidation_0-logloss:0.086248\n",
            "[243]\tvalidation_0-logloss:0.086263\n",
            "[244]\tvalidation_0-logloss:0.086293\n",
            "[245]\tvalidation_0-logloss:0.086222\n",
            "[246]\tvalidation_0-logloss:0.086398\n",
            "[247]\tvalidation_0-logloss:0.086347\n",
            "[248]\tvalidation_0-logloss:0.086276\n",
            "[249]\tvalidation_0-logloss:0.086448\n",
            "[250]\tvalidation_0-logloss:0.086294\n",
            "[251]\tvalidation_0-logloss:0.086312\n",
            "[252]\tvalidation_0-logloss:0.086364\n",
            "[253]\tvalidation_0-logloss:0.086394\n",
            "[254]\tvalidation_0-logloss:0.08649\n",
            "[255]\tvalidation_0-logloss:0.086441\n",
            "[256]\tvalidation_0-logloss:0.08629\n",
            "[257]\tvalidation_0-logloss:0.08646\n",
            "[258]\tvalidation_0-logloss:0.086391\n",
            "[259]\tvalidation_0-logloss:0.086441\n",
            "[260]\tvalidation_0-logloss:0.086461\n",
            "[261]\tvalidation_0-logloss:0.086491\n",
            "[262]\tvalidation_0-logloss:0.086445\n",
            "[263]\tvalidation_0-logloss:0.086466\n",
            "[264]\tvalidation_0-logloss:0.086319\n",
            "[265]\tvalidation_0-logloss:0.086488\n",
            "[266]\tvalidation_0-logloss:0.086538\n",
            "[267]\tvalidation_0-logloss:0.086471\n",
            "[268]\tvalidation_0-logloss:0.086501\n",
            "[269]\tvalidation_0-logloss:0.086522\n",
            "[270]\tvalidation_0-logloss:0.086689\n",
            "[271]\tvalidation_0-logloss:0.086738\n",
            "[272]\tvalidation_0-logloss:0.08683\n",
            "[273]\tvalidation_0-logloss:0.086684\n",
            "[274]\tvalidation_0-logloss:0.08664\n",
            "[275]\tvalidation_0-logloss:0.086496\n",
            "[276]\tvalidation_0-logloss:0.086355\n",
            "[277]\tvalidation_0-logloss:0.086519\n",
            "[278]\tvalidation_0-logloss:0.086567\n",
            "[279]\tvalidation_0-logloss:0.08659\n",
            "[280]\tvalidation_0-logloss:0.086679\n",
            "[281]\tvalidation_0-logloss:0.086637\n",
            "[282]\tvalidation_0-logloss:0.086499\n",
            "[283]\tvalidation_0-logloss:0.086356\n",
            "[284]\tvalidation_0-logloss:0.086405\n",
            "[285]\tvalidation_0-logloss:0.086429\n",
            "[286]\tvalidation_0-logloss:0.086456\n",
            "[287]\tvalidation_0-logloss:0.086504\n",
            "[288]\tvalidation_0-logloss:0.08637\n",
            "[289]\tvalidation_0-logloss:0.086457\n",
            "[290]\tvalidation_0-logloss:0.086453\n",
            "[291]\tvalidation_0-logloss:0.086322\n",
            "[292]\tvalidation_0-logloss:0.086284\n",
            "[293]\tvalidation_0-logloss:0.086148\n",
            "[294]\tvalidation_0-logloss:0.086196\n",
            "[295]\tvalidation_0-logloss:0.086221\n",
            "[296]\tvalidation_0-logloss:0.086308\n",
            "[297]\tvalidation_0-logloss:0.086178\n",
            "[298]\tvalidation_0-logloss:0.086263\n",
            "[299]\tvalidation_0-logloss:0.086131\n",
            "[300]\tvalidation_0-logloss:0.086179\n",
            "[301]\tvalidation_0-logloss:0.086052\n",
            "[302]\tvalidation_0-logloss:0.086016\n",
            "[303]\tvalidation_0-logloss:0.086101\n",
            "[304]\tvalidation_0-logloss:0.085977\n",
            "[305]\tvalidation_0-logloss:0.086059\n",
            "[306]\tvalidation_0-logloss:0.085971\n",
            "[307]\tvalidation_0-logloss:0.085998\n",
            "[308]\tvalidation_0-logloss:0.085999\n",
            "[309]\tvalidation_0-logloss:0.085877\n",
            "[310]\tvalidation_0-logloss:0.085923\n",
            "[311]\tvalidation_0-logloss:0.085948\n",
            "Stopping. Best iteration:\n",
            "[211]\tvalidation_0-logloss:0.085593\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 교재에 따르면 조기 중단으로 학습된 예측 성능은 약간 저조하나 큰 차이는 없다. 정확도 0.965 정도. 하지만 조기 중단을 너무 급하게 하면 당연히 안되겠지."
      ],
      "metadata": {
        "id": "cbe8Jb-H4oDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#사이킷런도 시각화 가능하다!\n",
        "from xgboost import plot_importance\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "fig, ax=plt.subplots(figsize=(10,12))\n",
        "plot_importance(xgb, ax=ax)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_elPYbD43jN",
        "outputId": "957f914d-99cf-4760-a86b-89a59b36169b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f8b6e28da60>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x864 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmEAAALJCAYAAAD8uvTIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzde3xV5Zn3/8/FQUTDoTUcIjRGpJWACUFS0w5UkyqjCB1PPJY+2AGEYdRfBRFG8WEEf50ZQSQKHlpErPaB8VS10p9UqxV37aCM5RBkiuBhzBQoRUABY4Mm4fr9kS1mZ5NkC9n73km+79drv9x73Wvd68pXJVfWvbIwd0dEREREUqtd6AJERERE2iI1YSIiIiIBqAkTERERCUBNmIiIiEgAasJEREREAlATJiIiIhKAmjARaRPM7P+Y2bLQdYiIfM70nDARaYqZlQO9gJo6m7/h7n8+zjknu/tvj6+6lsfMbgP6u/tVoWsRkXB0JUxEEvU9d8+o8zrmBqw5mFmHkOc/Vi21bhFpfmrCROSYmVk3M3vIzHaZ2U4z+1czax8dO8PMVpvZPjPba2b/bmbdo2PLgWzg/zOzCjO7ycyKzWxHvfnLzeyC6PvbzOwpM1thZgeBCY2d/yi13mZmK6Lvc8zMzWyimW03s4/M7Boz+6aZvWlm+83svjrHTjCzNWZ2n5kdMLOtZnZ+nfFTzexXZvahmb1rZv9Q77x1674G+D/A96Nf+6bofhPN7C0z+9jM/tvM/rHOHMVmtsPMZpjZB9Gvd2Kd8c5mVmpm/xOt7z/MrHN07Ftm9lr0a9pkZsXH9C9bRJqdmjAROR6PANVAf2AI8LfA5OiYAfOAU4Fc4GvAbQDu/kPgT3xxdW1Bgue7BHgK6A78exPnT0QR8HXg+8AiYDZwATAIuNLMzqu373tAJjAXeMbMvhodexzYEf1axwC3m9l3G6j7IeB24Ino1z44us8HwGigKzARuNvMzq4zR2+gG9AHmATcb2ZfiY4tBIYCfwN8FbgJOGxmfYBVwL9Gt88EnjazHl8iIxFJEjVhIpKoZ6NXU/ab2bNm1gu4GLjB3T9x9w+Au4GxAO7+rru/5O6fuvse4C7gvIanT8jr7v6sux+mtllp8PwJ+hd3P+TuLwKfAI+5+wfuvhP4PbWN3ec+ABa5e5W7PwFsA0aZ2deAYcDN0bnKgGXA3x+tbnevPFoh7r7K3d/zWr8DXgS+U2eXKuDH0fP/GqgAzjSzdsDVwDR33+nuNe7+mrt/ClwF/Nrdfx0990vAumhuIhKY7k0QkURdWvcmejM7B+gI7DKzzze3A7ZHx3sBi6ltJLpExz46zhq213l/WmPnT9DuOu8rj/I5o87nnR77m0z/Q+2Vr1OBD93943pjhQ3UfVRmNpLaK2zfoPbrOAnYXGeXfe5eXefzX6P1ZQInUnuVrr7TgP9lZt+rs60j8EpT9YhI8qkJE5FjtR34FMis1xx87nbAgTx3/9DMLgXuqzNe/1ezP6G28QAgem9X/WWzusc0df7m1sfMrE4jlg38Cvgz8FUz61KnEcsGdtY5tv7XGvPZzDoBT1N79Wylu1eZ2bPULuk2ZS9wCDgD2FRvbDuw3N3/Ie4oEQlOy5EickzcfRe1S2alZtbVzNpFb8b/fMmxC7VLZgei9yb9U70pdgP96nx+GzjRzEaZWUfgn4FOx3H+5tYTmGpmHc3sf1F7n9uv3X078Bowz8xONLN8au/ZWtHIXLuBnOhSIsAJ1H6te4Dq6FWxv02kqOjS7M+Au6K/INDezL4dbexWAN8zswuj20+M3uTf98t/+SLS3NSEicjx+HtqG4gt1C41PgVkRcf+X+Bs4AC1N4c/U+/YecA/R+8xm+nuB4DrqL2faie1V8Z20LjGzt/c/pPam/j3Av8GjHH3fdGxHwA51F4V+yUwt4nnn/0i+s99ZrYhegVtKvAktV/H/6b2KluiZlK7dPkH4EPgDqBdtEG8hNrfxtxD7ZWxf0J/9oukBT2sVUSkCWY2gdoHyw4PXYuItB76aUhEREQkADVhIiIiIgFoOVJEREQkAF0JExEREQmgRT4nrHv37t6/f//QZaSNTz75hJNPPjl0GWlFmcRSHvGUSSzlEU+ZxFIe8RLNZP369XvdPe6vC2uRTVivXr1Yt25d6DLSRiQSobi4OHQZaUWZxFIe8ZRJLOURT5nEUh7xEs3EzP7naNu1HCkiIiISgJowERERkQDUhImIiIgEoCZMREREJAA1YSIiIiIBqAkTERERCUBNmIiIiEgAasJEREREAlATJiIiIhKAmjARERGRANSEiYiIiASgJkxEREQkADVhIiIiIgGoCRMREREJQE2YiIiISABqwkREREQCUBMmIiIiLc62bdsoKCg48uratSuLFi06Ml5aWoqZsXfv3oBVNq5DMic3s6nAtcAW4FTgbGC2uy+Mjp8IvAp0itbylLvPTWZNIiIi0vKdeeaZlJWVAVBTU0OfPn247LLLANi+fTsvvvgi2dnZIUtsUlKbMOA64ALgM+A04NJ6458C33X3CjPrCPyHmT3v7msbm7SyqoacWauSUnBLNCOvmgnKI4YyiaU84imTWMojnjKJleo8yuePSnjfl19+mTPOOIPTTjsNgOnTp7NgwQIuueSSZJXXLJK2HGlmS4B+wPPAOHf/A1BVdx+vVRH92DH68mTVJCIiIq3P448/zg9+8AMAVq5cSZ8+fRg8eHDgqppm7snrecysHCh0973Rz7cBFZ8vR0a3tQfWA/2B+9395gbmmgJMAcjM7DF0zqIHk1Z3S9OrM+yuDF1FelEmsZRHPGUSS3nEUyaxUp1HXp9uCe1XVVXFmDFjePjhhznppJOYPn06d955JxkZGYwdO5YHHniAbt0Sm+vLqqioICMjo8n9SkpK1rt7Yf3tyV6ObJK71wAFZtYd+KWZneXu/3WU/ZYCSwGy+/X30s3BS08bM/KqUR6xlEks5RFPmcRSHvGUSaxU51E+rjih/VauXElRURGXX345mzdvZt++ffzoRz8CYO/evVx//fW88cYb9O7du9lrjEQiFBcnVufRpM1/Xe6+38xeAS4C4pqwujp3bM+2L7FW3NpFIpGE/2NtK5RJLOURT5nEUh7xlEmsdM3jscceO7IUmZeXxwcffHBkLCcnh3Xr1pGZmRmqvEYFfUSFmfWIXgHDzDoDI4CtIWsSERGRluGTTz7hpZde4vLLLw9dyjFJyZUwM+sNrAO6AofN7AZgIJAF/Dx6X1g74El3fy4VNYmIiEjLdvLJJ7Nv374Gx8vLy1NXzDFIahPm7jl1PvY9yi5vAkOSWYOIiIhIOtIT80VEREQCUBMmIiIiEoCaMBEREZEA1ISJiIiIBKAmTERERCQANWEiIiIiAagJExEREQlATZiIiIhIAGrCRERERAJQEyYiIiISgJowERERkQDUhImIiIgEoCZMRESkBdi/fz9jxoxhwIAB5Obm8vrrrx8ZKy0txczYu3dvwArlywrShJnZVDN7y8yeNrPXzexTM5sZohYREZGWYNq0aVx00UVs3bqVTZs2kZubC8D27dt58cUXyc7ODlyhfFkdAp33OuAC4DPgNODSL3NwZVUNObNWJaOuFmlGXjUTlEcMZRJLecRTJrGUR7xUZlI+f1Sj4wcOHODVV1/lkUceAeCEE07ghBNOAGD69OksWLCASy65JNllSjNL+ZUwM1sC9AOeB8a5+x+AqlTXISIi0lK8//779OjRg4kTJzJkyBAmT57MJ598wsqVK+nTpw+DBw8OXaIcA3P31J/UrBwodPe90c+3ARXuvrCRY6YAUwAyM3sMnbPowRRU2jL06gy7K0NXkV6USSzlEU+ZxFIe8VKZSV6fbo2Ob9u2jeuuu457772XgQMHcu+999KxY0c2bdrEnXfeSUZGBmPHjuWBBx6gW7fG5zpWFRUVZGRkJGXulirRTEpKSta7e2H97S2mCasru19/b3fl4uQV2MLMyKumdHOoleX0pExiKY94yiSW8oiXykyaWo78y1/+wre+9S3Ky8sB+P3vf89tt93G5s2bOemkkwDYsWMHp556Km+88Qa9e/du9hojkQjFxcXNPm9LlmgmZnbUJqxF/h/XuWN7tjXxH2xbEolEKB9XHLqMtKJMYimPeMoklvKIl06Z9O7dm6997Wts27aNM888k5dffpmzzz6bl19++cg+OTk5rFu3jszMzICVypfRIpswERGRtubee+9l3LhxfPbZZ/Tr14+HH344dElynII2YWbWG1gHdAUOm9kNwEB3PxiyLhERkXRTUFDAunXrGhz/fKlSWo4gTZi759T52DdEDSIiIiIh6Yn5IiIiIgGoCRMREREJQE2YiIiISABqwkREREQCUBMmIiIiEoCaMBEREZEA1ISJiIiIBKAmTERERCQANWEiIiIiAagJExEREQlATZiIiIhIAGrCREREjsH+/fsZM2YMAwYMIDc3l9dff50PP/yQESNG8PWvf50RI0bw0UcfhS5T0ljSmjAzm2pmb5mZm9mbZrbZzF4zs8F19vmZmX1gZv+VrDpERESSYdq0aVx00UVs3bqVTZs2kZuby/z58zn//PN55513OP/885k/f37oMiWNJfNK2HXACGAYcJ675wH/Aiyts88jwEVJrEFERKTZHThwgFdffZVJkyYBcMIJJ9C9e3dWrlzJ+PHjARg/fjzPPvtsyDIlzXVIxqRmtgToBzwP/MzdX4sOrQX6fr6fu79qZjlfdv7KqhpyZq1qhkpbhxl51UxQHjGUSSzlEU+ZxFIe8R656OQGx95//3169OjBxIkT2bRpE0OHDmXx4sXs3r2brKwsAHr37s3u3btTVa60QEm5Eubu1wB/Bkrc/e46Q5OobcxERERarOrqajZs2MC1117Lxo0bOfnkk+OWHs0MMwtUobQESbkSdjRmVkJtEzb8GI+fAkwByMzswZy86masrmXr1bn2p1j5gjKJpTziKZNYyiNeRUUFkUjkqGMffvghmZmZVFZWEolEOOOMM3j00Ufp2rUrTz/9NKeccgr79u2jS5cuDc7R0jSWR1t1vJmkpAkzs3xgGTDS3fcdyxzuvpTo/WTZ/fp76eaU9Y9pb0ZeNcojljKJpTziKZNYyiPeIxedTHFxcYPjd999N1lZWZx55plEIhG+853vAPDOO+9wxRVXMH/+fMaOHdvoHC1JJBJpNV9LczneTJL+f5yZZQPPAD9097ebY87OHduzbf6o5piqVYhEIpSPKw5dRlpRJrGURzxlEkt5xGvqCse9997LuHHj+Oyzz+jXrx8PP/wwhw8f5sorr+Shhx7itNNO48knn0xNsdIipeLHnjnAKcBPomvj1e5eCGBmjwHFQKaZ7QDmuvtDKahJRETkuBQUFLBu3bq47S+//HKAaqQlSloT5u450beTo6+j7fODZJ1fREREJJ3pifkiIiIiAagJExEREQlATZiIiIhIAGrCRERERAJQEyYiIiISgJowERERkQDUhImIiIgEoCZMREREJAA1YSIiIiIBqAkTERERCUBNmIiIiEgAasJEREREAlATJiLSgtXU1DBkyBBGjx4NgLsze/ZsvvGNb5Cbm8s999wTuEIRaUiHZE1sZlOBa4EBwGbAgI+Ba919U3Sf7sAy4CzAgavd/fVk1SQi0tosXryY3NxcDh48CMAjjzzC9u3b2bp1K+3ateODDz4IXKGINCRpTRhwHXABkA285e4fmdlIYClQFN1nMfCCu48xsxOAkxKZuLKqhpxZq5JRc4s0I6+aCcojhjKJpTzitYRMyuePanR8x44drFq1itmzZ3PXXXcB8NOf/pRHH32Udu1qFzp69uyZ9DpF5NgkZTnSzJYA/YDngSJ3/yg6tBboG92nG3Au8BCAu3/m7vuTUY+ISGt0ww03sGDBgiMNF8B7773HE088QWFhISNHjuSdd94JWKGINCYpV8Lc/Rozuwgocfe9dYYmUduYAZwO7AEeNrPBwHpgmrt/crQ5zWwKMAUgM7MHc/Kqk1F6i9Src+1P9fIFZRJLecRrCZlEIpEGx15//XWqqqr4+OOPKSsrY9++fUQiEf7617+yc+dOFi5cyKuvvsoVV1yR0H1hFRUVjZ6vLVImsZRHvOPNxNy9+aqpO7FZOVD4eRNmZiXAT4Dh7r7PzAqpvTI2zN3/08wWAwfd/dam5s7u19/bXbk4KXW3RDPyqindnMyV5ZZHmcRSHvFaQiaNLUfecsstLF++nA4dOnDo0CEOHjzI5Zdfzrp163j++ec5/fTTcXe6d+/OgQMHmjxXJBKhuLi4Gatv+ZRJLOURL9FMzGy9uxfW356S3440s3xqb8C/xN33RTfvAHa4+39GPz8FnJ2KekREWrp58+axY8cOysvLefzxx/nud7/LihUruPTSS3nllVcA+N3vfsc3vvGNwJWKSEOS/mOgmWUDzwA/dPe3P9/u7n8xs+1mdqa7bwPOB7YkMmfnju3Z1sQNq21JJBKhfFxx6DLSijKJpTzitdZMZs2axbhx47j77rvJyMhg2bJloUsSkQak4lr8HOAU4CdmBlBd55Lc9cC/R38z8r+BiSmoR0SkVSkuLj6yJNK9e3dWrUrv3/oUkVpJa8LcPSf6dnL0dbR9yoC4NVIRERGR1k5PzBcREREJQE2YiIiISABqwkREREQCUBMmIiIiEoCaMBEREZEA1ISJiIiIBKAmTERERCQANWEiIiIiAagJExEREQlATZiIiIhIAGrCRERERAJQEyYiIiISgJowEZE0V1NTw5AhQxg9ejQAEyZM4PTTT6egoICCggLKysoCVygix6JDiJOa2VTgWiAbeKdOLblAD3f/MERdIiLpaPHixeTm5nLw4MEj2+68807GjBkTsCoROV5BmjDgOuACd9/x+QYz+x4wPZEGrLKqhpxZq5JZX4syI6+aCcojhjKJpTzipUsm5fNHNTq+Y8cOVq1axezZs7nrrrtSVJWIpELKlyPNbAnQD3jezKbXGfoB8Fiq6xERSWc33HADCxYsoF272D+uZ8+eTX5+PtOnT+fTTz8NVJ2IHA9z99Sf1KwcKHT3vdHPJwE7gP4NXQkzsynAFIDMzB5D5yx6MEXVpr9enWF3Zegq0osyiaU84qVLJnl9ujU49vrrr7N27VqmT59OWVkZTzzxBPPmzWPfvn189atfpaqqitLSUk499VTGjx9/XHVUVFSQkZFxXHO0NsoklvKIl2gmJSUl6929sP72UMuR9X0PWNPYUqS7LwWWAmT36++lm9Ol9PBm5FWjPGIpk1jKI166ZFI+rrjBsd/85jesX7+eCRMmcOjQIQ4ePMiyZctYsWLFkX1OOOEEFi5cSHFxw/MkIhKJHPccrY0yiaU84h1vJuH/BKo1li+xFNm5Y3u2NXEfRVsSiUQa/YO8LVImsZRHvJaQybx585g3bx5QW+/ChQtZsWIFu3btIisrC3fn2Wef5ayzzgpcqYgci+BNmJl1A84Drgpdi4hISzBu3Dj27NmDu1NQUMCSJUtClyQixyB4EwZcBrzo7p+ELkREJF0VFxcfWfZYvXp12GJEpFkEacLcPafO+0eAR0LUISIiIhKKnpgvIiIiEoCaMBEREZEA1ISJiIiIBKAmTERERCQANWEiIiIiAagJExEREQlATZiIiIhIAGrCRERERAJQEyYiIiISgJowERERkQDUhImIiIgEoCZMREREJAA1YSIiKVRTU8OQIUMYPXo0AJMmTWLw4MHk5+czZswYKioqAlcoIqmS1CbMzKaa2Vtm5mb2ppltNrPXzGxwnX2mm9kfzey/zOwxMzsxmTWJiIS0ePFicnNzj3y+++672bRpE2+++SbZ2dncd999AasTkVTqkOT5rwMuALKBt9z9IzMbCSwFisysDzAVGOjulWb2JDAWeKSxSSurasiZtSq5lbcgM/KqmaA8YiiTWMojXnNnUj5/VJP77Nixg1WrVjF79mzuuusuALp27QqAu1NZWYmZNVtNIpLeknYlzMyWAP2A54Eid/8oOrQW6Ftn1w5AZzPrAJwE/DlZNYmIhHTDDTewYMEC2rWL/aN34sSJ9O7dm61bt3L99dcHqk5EUs3cPXmTm5UDhe6+t862mcAAd58c/TwN+DegEnjR3cc1MNcUYApAZmaPoXMWPZi0uluaXp1hd2XoKtKLMomlPOI1dyZ5fbo1Ov7666+zdu1apk+fTllZGU888QTz5s07Ml5TU8M999zDgAEDGDlyZPMVlqCKigoyMjJSft50pkxiKY94iWZSUlKy3t0L629P9nJkDDMrASYBw6OfvwJcApwO7Ad+YWZXufuK+se6+1JqlzHJ7tffSzentPS0NiOvGuURS5nEUh7xmjuT8nHFjY7/5je/Yf369UyYMIFDhw5x8OBBli1bxooVX/xx17FjRxYsWMAdd9zRbHUlKhKJUFxcnPLzpjNlEkt5xDveTFL2p7KZ5QPLgJHuvi+6+QLgfXffE93nGeBvgLgmrK7OHduzLYH7L9qKSCTS5DeAtkaZxFIe8VKdybx5845c+YpEIixcuJDly5fz7rvv0r9/f9ydX/3qVwwYMCBlNYlIWClpwswsG3gG+KG7v11n6E/At8zsJGqXI88H1qWiJhGR0Nyd8ePHc/DgQdydwYMH89Of/jR0WSKSIqm6EjYHOAX4SfQ3f6rdvdDd/9PMngI2ANXARqJLjiIirVVxcfGRJYw1a9aELUZEgklqE+buOdG3k6Ovo+0zF5ibzDpERERE0o2emC8iIiISgJowERERkQDUhImIiIgEoCZMREREJAA1YSIiIiIBqAkTERERCUBNmIiIiEgAasJEREREAlATJiIiIhKAmjARERGRANSEiYiIiASgJkxE5BjU1NQwZMgQRo8eDcB9991H//79MTP27t0buDoRaQmS1oSZ2VQze8vMnjaz183sUzObWW+fcjPbbGZlZrYuWbWIiDS3xYsXk5ube+TzsGHD+O1vf8tpp50WsCoRaUmSeSXsOmAEcC0wFVjYwH4l7l7g7oVJrEVEpNns2LGDVatWMXny5CPbhgwZQk5OTriiRKTF6ZCMSc1sCdAPeB74mbvfbWajmmv+yqoacmataq7pWrwZedVMUB4xlEks5RGvsUzK5zf+x9UNN9zAggUL+Pjjj5NRmoi0EUm5Eubu1wB/pvYq192N7Qq8aGbrzWxKMmoREWlOzz33HD179mTo0KGhSxGRFs7cPTkTm5UDhe6+N/r5NqDC3RfW2aePu+80s57AS8D17v5qA/NNAaYAZGb2GDpn0YNJqbsl6tUZdleGriK9KJNYyiNeY5nk9enW4HEPPvggL774Iu3bt+ezzz7jr3/9K9/5zneYPXs2AGPHjuWBBx6gW7eG50hHFRUVZGRkhC4jrSiTWMojXqKZlJSUrD/abVdJWY5MlLvvjP7zAzP7JXAOcNQmzN2XAksBsvv199LNQUtPKzPyqlEesZRJLOURr7FMyscVN3hccfEXY5FIhIULF/Lcc88d2XbiiScybNgwMjMzm6vUlIhEIjFfmyiT+pRHvOPNJNifymZ2MtDO3T+Ovv9b4MeJHNu5Y3u2NXHPRlsSiUQa/abRFimTWMojXnNncs8997BgwQL+8pe/kJ+fz8UXX8yyZcuabX4RaX2S3oSZWW9gHdAVOGxmNwADgUzgl2b2eR2PuvsLya5HRKS5FBcXH/kpeOrUqUydOjVsQSLSoiStCXP3nDof+x5ll4PA4GSdX0RERCSd6Yn5IiIiIgGoCRMREREJQE2YiIiISABqwkREREQCUBMmIiIiEoCaMBEREZEA1ISJiIiIBKAmTERERCQANWEiIiIiAagJExEREQlATZiIiIhIAGrCRERERAJQEyYiaePQoUOcc845DB48mEGDBjF37lwAJkyYwOmnn05BQQEFBQWUlZUFrlRE5Ph1SObkZjYVuBYYAGwGDPgYuNbdN5nZicCrQKdoLU+5+9xk1iQi6atTp06sXr2ajIwMqqqqGD58OCNHjgTgzjvvZMyYMYErFBFpPkltwoDrgAuAbOAtd//IzEYCS4Ei4FPgu+5eYWYdgf8ws+fdfW1jk1ZW1ZAza1WSS285ZuRVM0F5xFAmsdIpj/L5oxocMzMyMjIAqKqqoqqqCjNLVWkiIimVtOVIM1sC9AOeB4rc/aPo0FqgL4DXqohu7xh9ebJqEpH0V1NTQ0FBAT179mTEiBEUFRUBMHv2bPLz85k+fTqffvpp4CpFRI6fuSev5zGzcqDQ3ffW2TYTGODuk6Of2wPrgf7A/e5+cwNzTQGmAGRm9hg6Z9GDSau7penVGXZXhq4ivSiTWOmUR16fbgntV1FRwa233srUqVPp2rUrX/3qV6mqqqK0tJRTTz2V8ePHH1cdFRUVR666ifI4GmUSS3nESzSTkpKS9e5eWH97spcjY5hZCTAJGP75NnevAQrMrDvwSzM7y93/q/6x7r6U2mVMsvv199LNKS09rc3Iq0Z5xFImsdIpj/JxxQnvu2HDBvbt28fEiROPbDvhhBNYuHAhxcWJz3M0kUjkuOdoTZRHPGUSS3nEO95MUvbbkWaWDywDLnH3ffXH3X0/8ApwUapqEpH0smfPHvbv3w9AZWUlL730EgMGDGDXrl0AuDvPPvssZ511VsgyRUSaRUp+NDazbOAZ4Ifu/nad7T2AKnffb2adgRHAHU3N17lje7Y1cnNvWxOJRL7U1YW2QJnEail57Nq1i/Hjx1NTU8Phw4e58sorGT16NN/97nfZs2cP7k5BQQFLliwJXaqIyHFL1frEHOAU4CfR33Sqjq6NZgE/j94X1g540t2fS1FNIpJm8vPz2bhxY9z21atXB6hGRCS5ktqEuXtO9O3k6Kv++JvAkGTWICIiIpKO9MR8ERERkQDUhImIiIgEoCZMREREJAA1YSIiIiIBqAkTERERCUBNmIiIiEgAasJEREREAlATJiIiIhKAmjARERGRANSEiYiIiASgJkxEREQkADVhIiIiIgGoCRORZnfo0CHOOeccBg8ezKBBg5g7dy4AkyZNYvDgweTn5zNmzBgqKioCVyoiEk7SmjAzm2pmb5mZm9mbZrbZzF4zs8HR8TPNrKzO6wcfazQAACAASURBVKCZ3ZCsekQkdTp16sTq1avZtGkTZWVlvPDCC6xdu5a7776bTZs28eabb5Kdnc19990XulQRkWA6JHHu64ALgGzgLXf/yMxGAkuBInffBhQAmFl7YCfwy0QmrqyqIWfWquRU3QLNyKtmgvKIoUxiJSOP8vmjGhwzMzIyMgCoqqqiqqoKM6Nr164AuDuVlZWYWbPWJCLSkiTlSpiZLQH6Ac9T23B9FB1aC/Q9yiHnA++5+/8kox4RSb2amhoKCgro2bMnI0aMoKioCICJEyfSu3dvtm7dyvXXXx+4ShGRcMzdkzOxWTlQ6O5762ybCQxw98n19v0ZsMHdG1ybMLMpwBSAzMweQ+csejApdbdEvTrD7srQVaQXZRIrGXnk9emW0H4VFRXceuutTJ06ldNPPx2obdDuueceBgwYwMiRI5u3sARVVFQcuVonyuNolEks5REv0UxKSkrWu3th/e3JXI6MYWYlwCRgeL3tJwB/B9zS2PHuvpTapUyy+/X30s0pKz3tzcirRnnEUiaxkpFH+bjihPfdsGED+/btY+LEiUe2dezYkQULFnDHHXc0a12JikQiFBcXBzl3OlIe8ZRJLOUR73gzScl3KTPLB5YBI919X73hkdReBdud6HydO7ZnWyP3o7Q1kUjkS31DbAuUSaxU57Fnzx46duxI9+7dqays5KWXXuKmm27i3XffpX///rg7v/rVrxgwYEDKahIRSTdJb8LMLBt4Bvihu799lF1+ADyW7DpEJHV27drF+PHjqamp4fDhw1x55ZWMGjWK73znOxw8eBB3Z/Dgwfz0pz8NXaqISDCpuBI2BzgF+En0N6GqP18XNbOTgRHAP6agDhFJkfz8fDZu3Bi3fc2aNQGqERFJT0lrwtw9J/p2cvR1tH0+obZBExEREWlT9MR8ERERkQDUhImIiIgEoCZMREREJAA1YSIiIiIBqAkTERERCUBNmIiIiEgAasJEREREAlATJiIiIhKAmjARERGRANSEiYiIiASgJkxEREQkADVhIiIiIgGoCRORRh06dIhzzjmHwYMHM2jQIObOnQvAfffdR//+/TEz9u7dG7hKEZGWJ6lNmJlNNbO3zMzN7E0z22xmr5nZ4Hr7tTezjWb2XDLrEZEvr1OnTqxevZpNmzZRVlbGCy+8wNq1axk2bBi//e1vOe2000KXKCLSInVI8vzXARcA2cBb7v6RmY0ElgJFdfabBrwFdE1k0sqqGnJmrWruWlusGXnVTFAeMZRJrMbyKJ8/qtFjzYyMjAwAqqqqqKqqwswYMmRIs9cpItKWJO1KmJktAfoBzwNF7v5RdGgt0LfOfn2BUcCyZNUiIsenpqaGgoICevbsyYgRIygqKmr6IBERaZS5e/ImNysHCt19b51tM4EB7j45+vkpYB7QBZjp7qMbmGsKMAUgM7PH0DmLHkxa3S1Nr86wuzJ0FelFmcRqLI+8Pt0SnqeiooJbb72VqVOncvrppwMwduxYHnjgAbp1S3yedFBRUXHkCp8oj6NRJrGUR7xEMykpKVnv7oX1tyd7OTKGmZUAk4Dh0c+jgQ/cfb2ZFTd2rLsvpXYZk+x+/b10c0pLT2sz8qpRHrGUSazG8igfV/yl5tqwYQP79u1j4sSJAJx44okMGzaMzMzM4y0zpSKRCMXFxaHLSBvKI54yiaU84h1vJin7LmVm+dQuOY50933RzcOAvzOzi4ETga5mtsLdr2psrs4d27OtiftY2pJIJPKlv5G2dsok1vHksWfPHjp27Ej37t2prKzkpZde4uabb27eAkVE2qCUPKLCzLKBZ4Afuvvbn29391vcva+75wBjgdVNNWAiklq7du2ipKSE/Px8vvnNbzJixAhGjx7NPffcQ9++fdmxYwf5+flMnjw5dKkiIi1Kqq6EzQFOAX5iZgDVR1sbFZH0k5+fz8aNG+O2T506lalTpwaoSESkdUhqExa9wgUwOfpqbN8IEElmPSIiIiLpQk/MFxEREQlATZiIiIhIAGrCRERERAJQEyYiIiISgJowERERkQDUhImIiIgEoCZMREREJAA1YSIiIiIBqAkTERERCUBNmIiIiEgAasJEREREAlATJiIcOnSIc845h8GDBzNo0CDmzp0LwPvvv09RURH9+/fn+9//Pp999lngSkVEWo8gTZiZTTWzt8zs36Ofv2lm1WY2JkQ9Im1dp06dWL16NZs2baKsrIwXXniBtWvXcvPNNzN9+nTeffddvvKVr/DQQw+FLlVEpNXoEOi81wEXuPsOM2sP3AG8mOjBlVU15MxalbTiWpoZedVMUB4xlEmsRy46udFxMyMjIwOAqqoqqqqqMDNWr17No48+CsD48eO57bbbuPbaa5Ner4hIW5DyK2FmtgToBzxvZtOB64GngQ9SXYuIfKGmpoaCggJ69uzJiBEjOOOMM+jevTsdOtT+rNa3b1927twZuEoRkdYj5U2Yu18D/BkoAZ4ELgN+muo6RCRW+/btKSsrY8eOHbzxxhts3bo1dEkiIq1aqOXIzy0Cbnb3w2bW6I5mNgWYApCZ2YM5edUpKK9l6NW5dvlNvqBMYlVUVBCJRBLePycnhxUrVrBnzx5efvll2rdvzx//+Ec6d+78peZJZ182k9ZOecRTJrGUR7zjzSR0E1YIPB5twDKBi82s2t2frb+juy8FlgJk9+vvpZtDl54+ZuRVozxiKZNYj1x0MsXFxQ2O79mzh44dO9K9e3cqKyu59dZbufnmm9m3bx979uxh7NixPP7440ycOLHReVqSSCTSar6W5qA84imTWMoj3vFmEvS7lLuf/vl7M3sEeO5oDVh9nTu2Z9v8UcksrUWJRCKUjysOXUZaUSaxmvpJbdeuXYwfP56amhoOHz7MlVdeyejRoxk4cCBjx47ln//5nxkyZAiTJk1KTcEiIm2ALhWICPn5+WzcuDFue79+/XjjjTcCVCQi0voFacLcPeco2yakvhIRERGRMPTEfBEREZEA1ISJiIiIBKAmTERERCQANWEiIiIiAagJExEREQlATZiIiIhIAGrCRERERAJQEyYiIiISgJowERERkQDUhImIiIgEoCZMREREJAA1YSIiIiIBqAkTaSO2b99OSUkJAwcOZNCgQSxevBiATZs28e1vf5u8vDy+973vcfDgwcCVioi0DUlrwsxsqpm9ZWZuZm+a2WYze83MBkfHv2Zmr5jZFjP7o5lNS1YtIgIdOnSgtLSULVu2sHbtWu6//362bNnC5MmTmT9/Pps3b+ayyy7jzjvvDF2qiEib0CGJc18HXABkA2+5+0dmNhJYChQB1cAMd99gZl2A9Wb2krtvaWriyqoacmatSmLpLcuMvGomKI8YbTGT8vmjGh3PysoiKysLgC5dupCbm8vOnTt5++23OffccwEYMWIEF154If/yL/+S9HpFRNq6pFwJM7MlQD/geaDI3T+KDq0F+gK4+y533xB9/zHwFtAnGfWISKzy8nI2btxIUVERgwYNYuXKlQD84he/YPv27YGrExFpG8zdkzOxWTlQ6O5762ybCQxw98n19s0BXgXOcvej3pBiZlOAKQCZmT2Gzln0YFLqbol6dYbdlaGrSC9tMZO8Pt0aHKuoqCAjIwOAyspKpk2bxlVXXcW5557Ln/70J+69914OHDjAsGHDeOaZZ440Za1Z3UxEeRyNMomlPOIlmklJScl6dy+svz1lTZiZlQA/AYa7+746+2UAvwP+zd2fSWTu7H79vd2Vi5u/6BZqRl41pZuTubLc8rTFTBpbjoxEIhQXF1NVVcXo0aO58MILufHGG+P2e/vtt7nqqqt44403kllqWvg8E6mlPOIpk1jKI16imZjZUZuwlPx2pJnlA8uAS+o1YB2Bp4F/T7QBE5Fj4+5MmjSJ3NzcmAbsgw8+AODw4cP867/+K9dcc02oEkVE2pSkXyows2zgGeCH7v52ne0GPETtTft3fZk5O3dsz7YmbkJuSyKRCOXjikOXkVaUSbw1a9awfPly8vLyKCgoAOD222/nnXfe4f777wfg8ssvZ+LEiSHLFBFpM1KxXjMHOAX4SW3fRXX0ktww4IfAZjMri+77f9z91ymoSaTNGT58OA3dfjBtmp4QIyKSaklrwtw9J/p2cvRVf/w/AEvW+UVERETSmZ6YLyIiIhKAmjARERGRANSEiYiIiASgJkxEREQkADVhIiIiIgGoCRMREREJQE2YiIiISABqwkREREQCUBMmIiIiEoCaMBEREZEA1ISJiIiIBKAmTERERCQANWEircj27dspKSlh4MCBDBo0iMWLFwPw7rvv8q1vfYuCggIKCwt54403AlcqIiJJbcLMbKqZvWVmT5vZ62b2qZnNrLfPdDP7o5n9l5k9ZmYnJrMmkdasQ4cOlJaWsmXLFtauXcv999/Pli1beOCBB5g7dy5lZWX8+Mc/5qabbgpdqohIm9chyfNfB1wAfAacBlxad9DM+gBTgYHuXmlmTwJjgUcam7SyqoacWauSUnBLNCOvmgnKI0ZrzqR8/qgGx7KyssjKygKgS5cu5ObmsnPnTgAOHjwIwIEDBzj11FOTX6iIiDQqaU2YmS0B+gHPAz9z97vN7GjfPToAnc2sCjgJ+HOyahJpS8rLy9m4cSNFRUX86Ec/4p/+6Z+YOXMmhw8f5rXXXgtdnohIm2funrzJzcqBQnffG/18G1Dh7gvr7DMN+DegEnjR3cc1MNcUYApAZmaPoXMWPZi0uluaXp1hd2XoKtJLa84kr0+3JveprKxk2rRpXHXVVZx77rmUlpZSWFjIeeedxyuvvMJzzz1HaWlpCqpNXxUVFWRkZIQuI20oj3jKJJbyiJdoJiUlJevdvbD+9qBNmJl9BXga+D6wH/gF8JS7r2hs3ux+/b3dlYuTVndLMyOvmtLNyV5ZbllacyaNLUcCVFVVMXr0aC688EJuvPFGADIyMvj4448xM9ydbt26HVmebKsikQjFxcWhy0gbyiOeMomlPOIlmomZHbUJC/1d6gLgfXffA2BmzwB/AzTahHXu2J5tTXwjaksikQjl44pDl5FW2mom7s6kSZPIzc090oABnHLKKfzud7+juLiY1atX8/Wvfz1glSIiAuGbsD8B3zKzk6hdjjwfWBe2JJGWa82aNSxfvpy8vDwKCgoAuP3225k5cyYzZsygurqaE088kaVLlwauVEREUtKEmVlvapurrsBhM7uB2t+I/E8zewrYAFQDGwF9dxA5RsOHD+dotxhEIhHWr18foCIREWlIUpswd8+p87FvA/vMBeYmsw4RERGRdKMn5ouIiIgEoCZMREREJAA1YSIiIiIBqAkTERERCUBNmIiIiEgAasJEREREAlATJiIiIhKAmjARERGRANSEiYiIiASgJkxEREQkADVhIiIiIgGoCRMREREJQE2YSBravn07JSUlDBw4kEGDBrF48eIjY/feey8DBgxg0KBB3HTTTQGrFBGR49EhxEnNbCpwLdAVyADejw494+4/DlGTSDrp0KEDpaWlnH322Xz88ccMHTqUESNGsHv3blauXMmmTZvo1KkTH3zwQehSRUTkGAVpwoDrgAuA/sBMdx/9ZQ6urKohZ9aqpBTWEs3Iq2aC8ojREjIpnz+qwbGsrCyysrIA6NKlC7m5uezcuZMHH3yQWbNm0alTJwB69uyZklpFRKT5pXw50syWAP2A54EhqT6/SEtTXl7Oxo0bKSoq4u233+b3v/89RUVFnHfeefzhD38IXZ6IiBwjc/fUn9SsHCgEzgKeBnYAf6b2qtgfGzhmCjAFIDOzx9A5ix5MTbEtQK/OsLsydBXppSVkktenW5P7VFZWMm3aNK666irOPfdcJk6cyJAhQ7j++uvZunUrP/7xj3n00Ucxs0bnqaioICMjo7lKbxWUSSzlEU+ZxFIe8RLNpKSkZL27F9bfHroJ+ww47O4VZnYxsNjdv97U8dn9+nu7Kxc3tVubMSOvmtLNoVaW01NLyKSx5UiAqqoqRo8ezYUXXsiNN94IwEUXXcTNN99MSUkJAGeccQZr166lR48ejc4ViUQoLi5ulrpbC2USS3nEUyaxlEe8RDMxs6M2YUG/S7n7wTrvf21mPzGzTHff29hxnTu2Z1sT38DakkgkQvm44tBlpJWWnom7M2nSJHJzc480YACXXnopr7zyCiUlJbz99tt89tlnZGZmBqxURESOVUJNmJmdAexw90/NrBjIB/6vu+8/npObWW9gt7u7mZ1D7T1q+45nTpHWYM2aNSxfvpy8vDwKCgoAuP3227n66qu5+uqrOeusszjhhBP4+c9/3uRSpIiIpKdEr4Q9DRSaWX9gKbASeBS4+DjPPwa41syqgUpgrIdYHxVJM8OHD6eh/xVWrFiR4mpERCQZEm3CDrt7tZldBtzr7vea2cZjPam750Tf3hd9iYiIiLQpiT6iosrMfgCMB56LbuuYnJJEREREWr9Em7CJwLeBf3P3983sdGB58soSERERad0SWo509y1mdjOQHf38PnBHMgsTERERac0SuhJmZt8DyoAXop8LzOxXySxMREREpDVLdDnyNuAcYD+Au5dR+1cPiYiIiMgxSPjGfHc/UG/b4eYuRkRERKStSPQRFX80s/8NtDezrwNTgdeSV5aIiIhI65bolbDrgUHAp9Q+pPUAcEOyihIRERFp7Zq8EmZm7YFV7l4CzE5+SSIiIiKtX5NXwty9BjhsZt1SUI+IiIhIm5DoPWEVwGYzewn45PON7j41KVWJiIiItHKJ3hP2DHAr8Cqwvs5LRI7D9u3bKSkpYeDAgQwaNIjFixcDcNttt9GnTx8KCgooKCjg17/+deBKRUSkuSX6xPyfN+dJzWwqcC3QG9hO7eMuqoEb3P0/mvNcIumsQ4cOlJaWcvbZZ/Pxxx8zdOhQRowYAcD06dOZOXNm4ApFRCRZEmrCzOx9wOtvd/djfWDrdcAF1D789RN3dzPLB54EBjR1cGVVDTmzVh3jqVufGXnVTFAeMdIlk/L5oxodz8rKIisrC4AuXbqQm5vLzp07U1GaiIgEluhyZCHwzejrO8A9wIpjOaGZLaH2afvPA//g7p83dydzlEZPpK0oLy9n48aNFBUVAXDfffeRn5/P1VdfzUcffRS4OhERaW4JNWHuvq/Oa6e7LwIa/xG/4bmuAf4MlLj73WZ2mZltBVYBVx/LnCItXUVFBVdccQWLFi2ia9euXHvttbz33nuUlZWRlZXFjBkzQpcoIiLNzL64ENXITmZn1/nYjtorY9e6++BjOqlZOVDo7nvrbDsXmOPuFzRwzBRgCkBmZo+hcxY9eCynbpV6dYbdlaGrSC/pkklen6af7FJdXc0tt9zCN7/5Ta688sq48b/85S/ccsstPPzww8dcR0VFBRkZGcd8fGukTGIpj3jKJJbyiJdoJiUlJevdvbD+9kQfUVFa53018D4Q/93iOLj7q2bWz8wy6zZndcaXAksBsvv199LNiZbe+s3Iq0Z5xEqXTMrHFTc67u6MHz+eYcOGsWjRoiPbd+3adeResbvvvpuioiKKixufqzGRSOS4jm+NlEks5RFPmcRSHvGON5NEv0tNcvf/rrvBzE4/5rN+MUd/4L3ojflnA52AfU0d17lje7Y1ccNzWxKJRJr8Zt/WtJRM1qxZw/Lly8nLy6OgoACA22+/nccee4yysjLMjJycHB544IHAlYqISHNLtAl7Cjj7KNuGHuf5rwD+3syqgErg+57I+qhIKzF8+HCO9p/8xRdfHKAaERFJpUabMDMbQO1f3N3NzC6vM9QVOPFYT+ruOdG3d0RfIiIiIm1KU1fCzgRGA92B79XZ/jHwD8kqSkRERKS1a7QJc/eVwEoz+7a7v56imkRERERavUTvCdtoZv8PtUuTR5Yh3V3P9RIRERE5Bok+MX85tX/P44XA74C+1C5JioiIiMgxSLQJ6+/ut1L79zz+nNqn5RclrywRERGR1i3RJqwq+s/9ZnYW0A3omZySRERERFq/RO8JW2pmXwFuBX4FZABzklaViIiISCuXUBPm7suib38H9EteOSIiIiJtQ0LLkWbWy8weMrPno58Hmtmk5JYmIiIi0nolek/YI8BvgFOjn98GbkhGQSIiIiJtQaJNWKa7PwkcBnD3aqAmaVWJiIiItHKJNmGfmNkpgAOY2beAA0mrSkRERKSVS7QJu5Ha34o8w8zWAP8XuD5pVYkEsn37dkpKShg4cCCDBg1i8eLFAPziF79g0KBBtGvXjnXr1gWuUkREWoNGmzAzywZw9w3AecDfAP8IDHL3N5s4dqqZvWVmT5vZ62b2qZnNrDN+ppmV1XkdNDPdZyZBdejQgdLSUrZs2cLatWu5//772bJlC2eddRbPPPMM5557bugSRUSklWjqERXPAmdH3z/h7ld8ibmvAy4APgNOAy6tO+ju24ACADNrD+wEfpnIxJVVNeTMWvUlSmndZuRVM0F5xGgsk/L5oxo8Lisri6ysLAC6dOlCbm4uO3fuZMSIEUmpU0RE2q6mliOtzvuEnw9mZkui+z8PjHP3P/DFU/eP5nzgPXf/n0TPIZJs5eXlbNy4kaIi/Q1dIiLS/Jq6EuYNvG/8IPdrzOwioMTd9yZwyFjgscZ2MLMpwBSAzMwezMmrTrScVq9X59orP/KFxjKJRCJNHl9ZWcm0adOYPHkyGzZsOLJ9//79rF+/noqKiuYqNSUqKioS+rrbEmUSS3nEUyaxlEe8482kqSZssJkdpPaKWOfoe6Kf3d27HvOZP5/I7ATg74BbGtvP3ZcCSwGy+/X30s2J/o1Lrd+MvGqUR6zGMikfV9zosVVVVYwePZprrrmGG2+8MWase/fuDB06lMLCwuYqNSUikQjFxcWhy0gryiSW8oinTGIpj3jHm0mj37ndvf0xz5y4kcAGd9+dgnOJNMrdmTRpErm5uXENmIiISHNKh8snP6CJpcj6Ondsz7ZGbq5uayKRSJNXd9qaY81kzZo1LF++nLy8PAoKCgC4/fbb+fTTT7n++uvZs2cPo0aNoqCggN/85jfNXLWIiLQlSW/CzKw3sA7oChyOPoZioLsfNLOTgRHUPvZCJLjhw4fjfvTbHy+77LIUVyMiIq1Z0powd8+p87FvA/t8ApySrBpERERE0lWiT8wXERERkWakJkxEREQkADVhIiIiIgGoCRMREREJ4P9v7/6j9KzrO/8/307IMWZC3DJBQkIcZ3FJIkggOQKnmO+MAo2FrdDl1EK0QkhzMLYJWr4u6PebFb+nS9o1Cs3aZQcwtFahu2CtRyDiAaZRASWBhCBhuqzcK7DyI8oPZ4jm1/v7x9x05547mZmQ3POZyTwf5+Rw39f1ua/rPa+TGV/e15V7LGGSJEkFWMIkSZIKsIRJkiQVYAmTJEkqwBImSZJUgCVMkiSpAEuYJElSAZYwSZKkAixhGtOWLFnC0UcfzYknnvgv2zZv3szy5cuZN28eCxYs4Mc//nHBCSVJ2reGlrCIWBER2yIiI+KxiNgaEQ9ExMn91iyKiO6IeCoirmrkPDr8XHLJJaxfv75m22c+8xk+/vGPs3nzZr7whS/wmc98ptB0kiTt34QGH385cBYwC9iWmS9HxIeATuC0iGgCvgKcDTwLPBwR387MJwY76I5de2i96s4Gjz52/NlJu7nkMM2jsvrcQfcvXLiQSqVSsy0i6O3tBeDVV1/l2GOPbdR4kiS9aQ0rYRFxA9AG3A18NTMfqO56CJhZffw+4KnM/Gn1NbcBHwYGLWHSYK677jra29tZt24de/fu5YEHHhj6RZIkjbDIzMYdPKICLMjM7f22XQnMzsylEXEhsCgzl1b3fQw4LTP/ZB/HWgYsA2hpmTZ/1XU3NmzuseYdk+CFHaWnaIyTZkwdcs3zzz/P1Vdfzbp16wD4q7/6K0444QR+53d+h/vvv5/vfOc7rFmzptGjjmo9PT00NzeXHmNUMZNa5lHPTGqZR73hZtLR0bEpMxcM3D6iJSwiOoC/Bs7MzF8cSAnrb1bb8fmWP7i+YXOPNX920m7WbG30leUyhrocCVCpVDjvvPN4/PHHAZg6dSrf+ta36OjoIDOZOnUqr732WqNHHdW6urpob28vPcaoYia1zKOemdQyj3rDzSQi9lnCRux/uSPivcBNwIcy8xfVzc8Bx/VbNrO6bVCTjmiiexj/4zxedHV1UVncXnqMUePYY49ly5YtdHR0cN999/Hud7+79EiSJNUZkRIWEbOAbwIfy8x/7rfrYeDdEfEu+srXHwIXj8RMOjxcdNFFdHV1sX37dmbOnMk111zDjTfeyJIlS1i3bh1vfetb6ezsLD2mJEl1RuqdsFXAUcBfRwTA7sxckJm7I+JPgO8CTfTdwP+TEZpJh4Fbb711n9s7Ozt921ySNKo1tIRlZmv14dLqn32tuQu4q5FzSJIkjTZ+Yr4kSVIBljBJkqQCLGGSJEkFWMIkSZIKsIRJkiQVYAmTJEkqwBImSZJUgCVMkiSpAEuYJElSAZYwSZKkAixhkiRJBVjCJEmSCrCEFfLKK69w4YUXMnv2bObMmcODDz5YeiRJkjSCJpQ4aUSsAD4B/BTYCfxr4NfAksx8vMRMI23lypUsWrSI22+/nZ07d/L666+XHkmSJI2gIiUMWA6cBawEejLzgoiYDXwF+OBQL96xaw+tV93Z4BEPTmX1ufvd9+qrr7JhwwZuueUWACZOnMjEiRNHaDJJkjQajPjlyIi4AWgD7qavjN0HkJlPAq0R8Y6RnmmkPf3000ybNo1LL72UU045haVLl9Lb21t6LEmSNIIiM0f+pBEVYAHwaWBSZn4qIt4HPACclpmb9vGaZcAygJaWafNXXXfjCE584E6aMXW/+7q7u1m+fDlr165l7ty5rF27lsmTJ7NkyZI3da6enh6am5vf7KiHJTOpZR71zKSWedQzk1rmUW+4mXR0Y5v/zgAAIABJREFUdGzKzAUDt5cuYTuB64FTgK3AbOCPM3PzYK+f1XZ8vuUPrm/0mAdlsMuRzz//PKeffjqVSgWA73//+6xevZo773xzl1i7urpob29/U689XJlJLfOoZya1zKOemdQyj3rDzSQi9lnCSt0TBkBmvgZcChARATxN3836g5p0RBPdg5Sc0e6YY47huOOOo7u7mxNOOIF7772XuXPnlh5LkiSNoKIlLCLeDryemTuBpcCGajE77K1du5bFixezc+dO2traWLduXemRJEnSCCpawoA5wN9ERAI/AS4rPM+ImTdvHhs3biw9hiRJKqRICcvM1urD7cC/KTGDJElSSX5iviRJUgGWMEmSpAIsYZIkSQVYwiRJkgqwhEmSJBVgCZMkSSrAEiZJklSAJUySJKkAS5gkSVIBljBJkqQCLGGSJEkFWMIKeeWVV7jwwguZPXs2c+bM4cEHHyw9kiRJGkENK2ERsSIitkXEHRHxYET8JiKuHLDm7RFxe0Q8WV17RqPmGW1WrlzJokWLePLJJ9myZQtz5swpPZIkSRpBExp47OXAWcBO4J3A+ftYcz2wPjMvjIiJwNuGc+Adu/bQetWdh2zQRqisPne/+1599VU2bNjALbfcAsDEiROZOHHiCE0mSZJGg4a8ExYRNwBtwN3A4sx8GNg1YM1UYCFwM0Bm7szMVxoxz2jz9NNPM23aNC699FJOOeUUli5dSm9vb+mxJEnSCGpICcvMy4H/DXRk5pf3s+xdwEvAuoh4NCJuiojJjZhntNm9ezePPPIIn/jEJ3j00UeZPHkyq1evLj2WJEkaQZGZjTlwRAVYkJnbq88/D/Rk5herzxcADwG/nZk/iojrgdcy8//dz/GWAcsAWlqmzV913Y0NmftQOWnG1P3u++Uvf8ny5cu57bbbAHjsscf4xje+8aaLWE9PD83NzW/qtYcrM6llHvXMpJZ51DOTWuZRb7iZdHR0bMrMBQO3N/KesKE8CzybmT+qPr8duGp/izOzE+gEmNV2fK7ZWnL0oVUWtw+6/8tf/jLTp0/nhBNOoKuri/e///20tw/+mv3p6up60689XJlJLfOoZya1zKOemdQyj3oHm0mxJpOZz0fEMxFxQmZ2Ax8EnhjOaycd0UT3IDe+jwVr165l8eLF7Ny5k7a2NtatW1d6JEmSNIIaXsIi4hhgI3AksDcirgDmZuZrwJ8CX6/+y8ifApc2ep7RYt68eWzcuLH0GJIkqZCGlbDMbO33dOZ+1mwG6q6RSpIkHe78xHxJkqQCLGGSJEkFWMIkSZIKsIRJkiQVYAmTJEkqwBImSZJUgCVMkiSpAEuYJElSAZYwSZKkAixhkiRJBVjCJEmSCrCESZIkFWAJK+SVV17hwgsvZPbs2cyZM4cHH3yw9EiSJGkENbSERcSKiNgWEXdExIMR8ZuIuHLAmkUR0R0RT0XEVY2cZzRZuXIlixYt4sknn2TLli3MmTOn9EiSJGkETWjw8ZcDZwE7gXcC5/ffGRFNwFeAs4FngYcj4tuZ+cRgB92xaw+tV93ZmIkPkcrqc/e779VXX2XDhg3ccsstAEycOJGJEyeO0GSSJGk0aNg7YRFxA9AG3A0szsyHgV0Dlr0PeCozf5qZO4HbgA83aqbR4umnn2batGlceumlnHLKKSxdupTe3t7SY0mSpBEUmdm4g0dUgAWZub36/PNAT2Z+sfr8QmBRZi6tPv8YcFpm/sk+jrUMWAbQ0jJt/qrrbmzY3IfCSTOm7ndfd3c3y5cvZ+3atcydO5e1a9cyefJklixZ8qbO1dPTQ3Nz85sd9bBkJrXMo56Z1DKPemZSyzzqDTeTjo6OTZm5YOD2Rl+OPGQysxPoBJjVdnyu2Tq6R68sbt/vvtmzZ3PttdeyfPlyAJqamli9ejXt7ft/zWC6urre9GsPV2ZSyzzqmUkt86hnJrXMo97BZlL6X0c+BxzX7/nM6rbD2jHHHMNxxx1Hd3c3APfeey9z584tPJUkSRpJpd9Oehh4d0S8i77y9YfAxUO9aNIRTXQPcuP7WLB27VoWL17Mzp07aWtrY926daVHkiRJI2hESlhEHANsBI4E9kbEFcDczHwtIv4E+C7QBHw1M38yEjOVNm/ePDZu3Fh6DEmSVEhDS1hmtvZ7OnM/a+4C7mrkHJIkSaNN6XvCJEmSxiVLmCRJUgGWMEmSpAIsYZIkSQVYwiRJkgqwhEmSJBVgCZMkSSrAEiZJklSAJUySJKkAS5gkSVIBljBJkqQCLGGSJEkFNPQXeAtaW1uZMmUKTU1NTJgwgY0bN5YeSZIkjQJFSlhErAA+ATwC3AhcBxwBbM/M/6vETI10//3309LSUnoMSZI0ipR6J2w5cBbQAzwALMrMn0XE0cN58Y5de2i96s5GzjcsldXnlh5BkiSNUSN+T1hE3AC0AXcDnwS+mZk/A8jMF0d6nkaLCM455xzmz59PZ2dn6XEkSdIoEZk58ieNqAALgP+HvsuQ7wGmANdn5t/u5zXLgGUALS3T5q+67saRGXYQJ82YOuSal156iWnTpvHyyy9z5ZVXsmLFCk4++eRDOkdPTw/Nzc2H9JhjnZnUMo96ZlLLPOqZSS3zqDfcTDo6OjZl5oKB20vfmD8BmA98EJgEPBgRD2XmPw9cmJmdQCfArLbjc83W0qNDZXH7Aa3fsmULu3btor39wF43lK6urkN+zLHOTGqZRz0zqWUe9cyklnnUO9hMSjeZZ4FfZGYv0BsRG4CTgboS1t+kI5roHgP3Y/X29rJ3716mTJlCb28v99xzD6tWrSo9liRJGgVKl7B/BP5zREwAJgKnAV8uO9Kh88ILL3DBBRcAsHv3bi6++GIWLVpUeCpJkjQaFC1hmbktItYDjwF7gZsy8/GSMx1KbW1tbNmypfQYkiRpFCpSwjKztd/j/wT8pxJzSJIkleKvLZIkSSrAEiZJklSAJUySJKkAS5gkSVIBljBJkqQCLGGSJEkFWMIkSZIKsIRJkiQVYAmTJEkqwBImSZJUgCVMkiSpAEuYJElSAUV+gfd40traypQpU2hqamLChAls3Lix9EiSJGkUaGgJi4gVwCeAJ4BjgVOBz2XmFwesawI2As9l5nmNnKmE+++/n5aWltJjSJKkUaTR74QtB84CdgLvBM7fz7qVwDbgyOEcdMeuPbRedechGfBgVFafW3oESZI0RjXsnrCIuAFoA+4GFmfmw8CufaybCZwL3NSoWUqKCM455xzmz59PZ2dn6XEkSdIoEZnZuINHVIAFmbm9+vzzQE//y5ERcTtwLTAFuHJ/lyMjYhmwDKClZdr8Vdfd2LC5h+ukGVOHXPPSSy8xbdo0Xn75Za688kpWrFjBySeffEjn6Onpobm5+ZAec6wzk1rmUc9MaplHPTOpZR71hptJR0fHpsxcMHB70RvzI+I84MXM3BQR7YOtzcxOoBNgVtvxuWZr+X9TUFncfkDrt2zZwq5du2hvP7DXDaWrq+uQH3OsM5Na5lHPTGqZRz0zqWUe9Q42k9JN5reB34uI3wXeChwZEX+XmR8d7EWTjmiiewzcj9Xb28vevXuZMmUKvb293HPPPaxatar0WJIkaRQoWsIy82rgaoDqO2FXDlXAxpIXXniBCy64AIDdu3dz8cUXs2jRosJTSZKk0WBESlhEHEPfR1AcCeyNiCuAuZn52kicv5S2tja2bNlSegxJkjQKNbSEZWZrv6czh1jbBXQ1cBxJkqRRw19bJEmSVIAlTJIkqQBLmCRJUgGWMEmSpAIsYZIkSQVYwiRJkgqwhEmSJBVgCZMkSSrAEiZJklSAJUySJKkAS5gkSVIBI/ILvMez1tZWpkyZQlNTExMmTGDjxo2lR5IkSaNAw0pYRKwAPgE8ARwLnAp8LjO/WN1/HPC3wDuABDoz8/pGzVPS/fffT0tLS+kxJEnSKNLId8KWA2cBO4F3AucP2L8b+LPMfCQipgCbIuJ7mfnEUAfesWsPrVfdecgHPlCV1eeWHkGSJI1RDbknLCJuANqAu4HFmfkwsKv/msz8eWY+Un38K2AbMKMR85QUEZxzzjnMnz+fzs7O0uNIkqRRoiHvhGXm5RGxCOjIzO1DrY+IVuAU4EeNmKekH/zgB8yYMYMXX3yRs88+m9mzZ7Nw4cLSY0mSpMIiMxtz4IgKsOCNEhYRnwd63rgnrN+6ZuCfgD/PzG8OcrxlwDKAlpZp81ddd2ND5j4QJ82YekDrb7nlFiZNmsRHPvKRQzpHT08Pzc3Nh/SYY52Z1DKPemZSyzzqmUkt86g33Ew6Ojo2ZeaCgduL/uvIiDgCuAP4+mAFDCAzO4FOgFltx+eareX/YWdlcfug+3t7e9m7dy9Tpkyht7eXz372s6xatYr29sFfd6C6uroO+THHOjOpZR71zKSWedQzk1rmUe9gMynWZCIigJuBbZn5pQN57aQjmugeAzfFv/DCC1xwwQUA7N69m4svvphFixYVnkqSJI0GDS9hEXEMsBE4EtgbEVcAc4H3Ah8DtkbE5uryz2bmXY2eaaS0tbWxZcuW0mNIkqRRqGElLDNb+z2duY8lPwCiUeeXJEkazfy1RZIkSQVYwiRJkgqwhEmSJBVgCZMkSSrAEiZJklSAJUySJKkAS5gkSVIBljBJkqQCLGGSJEkFWMIkSZIKsIRJkiQVYAmTJEkqwBJ2COzZs4dTTjmF8847r/QokiRpjGhYCYuIFRGxLSIyIh6LiK0R8UBEnNxvTaW6fXNEbGzULI12/fXXM2fOnNJjSJKkMWRCA4+9HDgLmAVsy8yXI+JDQCdwWr91HZm5/UAOvGPXHlqvuvPQTTqIyupzB93/7LPPcuedd/K5z32OL33pSyMykyRJGvsa8k5YRNwAtAF3A6dl5svVXQ8BMxtxzlKuuOIK/vIv/5K3vMUru5IkafgiMxtz4IgKsKD/u1wRcSUwOzOXVp8/DbwMJPBfM7NzkOMtA5YBtLRMm7/quhsbMvdAJ82Yut99Dz74IA899BCf+tSn2Lx5M3//93/PtddeOyJz9dfT00Nzc/OIn3c0M5Na5lHPTGqZRz0zqWUe9YabSUdHx6bMXDBweyMvR9aIiA7gMuDMfpvPzMznIuJo4HsR8WRmbtjX66sFrRNgVtvxuWbryIxeWdy+333f/e532bRpE5dccgm//vWvee2117jpppv4u7/7uxGZ7Q1dXV20t7eP6DlHOzOpZR71zKSWedQzk1rmUe9gMxmRa2gR8V7gJuDDmfmLN7Zn5nPV/74I/APwvpGY51C59tprefbZZ6lUKtx222184AMfGPECJkmSxqaGv50UEbOAbwIfy8x/7rd9MvCWzPxV9fE5wBeGc8xJRzTRPcQN85IkSaPZSFzTWwUcBfx1RADsrl4XfQfwD9VtE4BvZOb6EZinIdrb232bVpIkDVvDSlhmtlYfLq3+Gbj/p8DJA7dLkiSNB36ugiRJUgGWMEmSpAIsYZIkSQVYwiRJkgqwhEmSJBVgCZMkSSrAEiZJklSAJUySJKkAS5gkSVIBljBJkqQCLGGSJEkFWMIkSZIKsIRVPfPMM3R0dDB37lze8573cP3115ceSZIkHcYaVsIiYkVEbIuIOyLiwYj4TURcOWDNVyPixYh4vFFzDNeECRNYs2YNTzzxBA899BBf+cpXeOKJJ0qPJUmSDlMTGnjs5cBZwE7gncD5+1hzC/Cfgb89kAPv2LWH1qvuPKBhKqvPHXT/9OnTmT59OgBTpkxhzpw5PPfcc8ydO/eAziNJkjQcDXknLCJuANqAu4HFmfkwsGvguszcAPyyETMcjEqlwqOPPsppp51WehRJknSYisxszIEjKsCCzNxeff55oCczvzhgXSvwncw8cYjjLQOWAbS0TJu/6robD2iek2ZMHda6HTt2sHLlSj760Y+ycOHCAzpHKT09PTQ3N5ceY1Qxk1rmUc9MaplHPTOpZR71hptJR0fHpsxcMHB7Iy9HHlKZ2Ql0AsxqOz7XbD2w0SuL24dcs2vXLs477zwuv/xyPv3pT7+ZMYvo6uqivb299BijipnUMo96ZlLLPOqZSS3zqHewmYyZEtbfpCOa6B7iHq8DlZlcdtllzJkzZ0wVMEmSNDb5ERVVP/zhD/na177Gfffdx7x585g3bx533XVX6bEkSdJhquHvhEXEMcBG4Ehgb0RcAczNzNci4lagHWiJiGeB/5CZNzd6pn0588wzadT9cZIkSQM1rIRlZmu/pzP3s+aiRp1fkiRpNPNypCRJUgGWMEmSpAIsYZIkSQVYwiRJkgqwhEmSJBVgCZMkSSrAEiZJklSAJUySJKkAS5gkSVIBljBJkqQCLGGSJEkFWMIkSZIKsIRVPfPMM3R0dDB37lze8573cP3115ceSZIkHcYmlDhpRKwAPgE8WZ1hVvW/X8zMdSVmmjBhAmvWrOHUU0/lV7/6FfPnz+fss89m7ty5JcaRJEmHuSIlDFgOnAX8ETA1M/9tREwDuiPi65m5c7AX79i1h9ar7jygE1ZWnzvo/unTpzN9+nQApkyZwpw5c3juuecsYZIkqSFG/HJkRNwAtAF3AwlMiYgAmoFfArtHeqaBKpUKjz76KKeddlrpUSRJ0mEqMnPkTxpRARYAvwG+DcwGpgAfycx9vsUVEcuAZQAtLdPmr7ruxgM650kzpg5r3Y4dO1i5ciUf/ehHWbhw4QGdo5Senh6am5tLjzGqmEkt86hnJrXMo56Z1DKPesPNpKOjY1NmLhi4vdTlyDf8DrAZ+ADwr4HvRcT3M/O1gQszsxPoBJjVdnyu2Xpgo1cWtw+5ZteuXZx33nlcfvnlfPrTnz6g45fU1dVFe3t76TFGFTOpZR71zKSWedQzk1rmUe9gMyldwi4FVmff23FPRcTT9L0r9uPBXjTpiCa6h7jH60BlJpdddhlz5swZUwVMkiSNTaU/ouJnwAcBIuIdwAnAT0sM8sMf/pCvfe1r3HfffcybN4958+Zx1113lRhFkiSNA6XfCfv/gFsiYisQwL/PzO0lBjnzzDMpcX+cJEkan4qUsMxs7ff0nBIzSJIklVT6cqQkSdK4ZAmTJEkqwBImSZJUgCVMkiSpAEuYJElSAZYwSZKkAixhkiRJBVjCJEmSCrCESZIkFWAJkyRJKsASJkmSVMC4KmFLlizh6KOP5sQTTyw9iiRJGucaVsIiYkVEbIuIOyLiwYj4TURcOWDNyoh4PCJ+EhFXNGqWN1xyySWsX7++0aeRJEka0oQGHns5cBawE3gncH7/nRFxIvDHwPuqa9ZHxHcy86mhDrxj1x5ar7qzbntl9bmDvm7hwoVUKpVhji9JktQ4DXknLCJuANqAu4HFmfkwsGvAsjnAjzLz9czcDfwT8PuNmEeSJGm0aUgJy8zLgf8NdGTml/ez7HHg/RFxVES8Dfhd4LhGzCNJkjTaNPJy5KAyc1tE/AVwD9ALbAb27G99RCwDlgG0tExj1Um769Z0dXUNed7nn3+e3t7eYa0dK3p6eg6rr+dQMJNa5lHPTGqZRz0zqWUe9Q42k2IlDCAzbwZuBoiI/wg8O8jaTqATYFbb8blma/3olcXtQ56zUqkwefJk2tuHXjtWdHV1HVZfz6FgJrXMo56Z1DKPemZSyzzqHWwmRUtYRBydmS9GxCz67gc7fTivm3REE91D3IS/LxdddBFdXV1s376dmTNncs0113DZZZcd8HEkSZIOVsNLWEQcA2wEjgT2Vj+KYm5mvgbcERFH0XfT/icz85VGznLrrbc28vCSJEnD1rASlpmt/Z7O3M+a9zfq/JIkSaPZuPrEfEmSpNHCEiZJklSAJUySJKkAS5gkSVIBljBJkqQCLGGSJEkFWMIkSZIKsIRJkiQVYAmTJEkqwBImSZJUgCVMkiSpAEuYJElSAeOqhC1ZsoSjjz6aE088sfQokiRpnCtSwiJiRURsi4ivR8RfRcRTEfFYRJzayPNecsklrF+/vpGnkCRJGpYJhc67HDgLeC/wp8C7gdOA/1L976B27NpD61V31m2vrD530NctXLiQSqVy4NNKkiQdYiNewiLiBqANuBv4N8AlmZnAQxHx9oiYnpk/H+m5JEmSRlL09Z8RPmlEBVgA3AKszswfVLffC/z7zNy4j9csA5YBtLRMm7/quhvrjnvSjKlDnvv555/n6quvZt26dQfxFYwuPT09NDc3lx5jVDGTWuZRz0xqmUc9M6llHvWGm0lHR8emzFwwcHupy5EHLDM7gU6AWW3H55qt9aNXFrcPeZxKpcLkyZNpbx967VjR1dV1WH09h4KZ1DKPemZSyzzqmUkt86h3sJmULmHPAcf1ez6zum1Qk45oonuI+78kSZJGs9IfUfFt4I+iz+nAq428H+yiiy7ijDPOoLu7m5kzZ3LzzTc36lSSJEmDKv1O2F3A7wJPAa8DlzbyZLfeemsjDy9JkjRsRUpYZrb2e/rJEjNIkiSVVPpypCRJ0rhkCZMkSSrAEiZJklSAJUySJKkAS5gkSVIBljBJkqQCLGGSJEkFWMIkSZIKsIRJkiQVYAmTJEkqwBImSZJUgCVMkiSpgHFVwpYsWcLRRx/NiSeeWHoUSZI0zjWshEXEiojYFhEZEY9FxNaIeCAiTu63ZmVEPB4RP4mIKxo1yxsuueQS1q9f3+jTSJIkDWlCA4+9HDgLmAVsy8yXI+JDQCdwWkScCPwx8D5gJ7A+Ir6TmU8NdeAdu/bQetWdddsrq88d9HULFy6kUqkc6NchSZJ0yDXknbCIuAFoA+4GTsvMl6u7HgJmVh/PAX6Uma9n5m7gn4Dfb8Q8kiRJo01kZmMOHFEBFmTm9n7brgRmZ+bSiJgD/CNwBrADuBfYmJl/up/jLQOWAbS0TJu/6rob69acNGPqkHM9//zzXH311axbt+6Av6bRqqenh+bm5tJjjCpmUss86plJLfOoZya1zKPecDPp6OjYlJkLBm5v5OXIGhHRAVwGnAmQmdsi4i+Ae4BeYDOwZ3+vz8xO+i5lMqvt+FyztX70yuL2IeeoVCpMnjyZ9vah144VXV1dh9XXcyiYSS3zqGcmtcyjnpnUMo96B5vJiJSwiHgvcBPwocz8xRvbM/Nm4Obqmv8IPDuc4006oonuIe7/kiRJGs0a/hEVETEL+Cbwscz85wH7ju635veBbzRylosuuogzzjiD7u5uZs6cyc0339zI00mSJO3XSLwTtgo4CvjriADY3e+66B0RcRSwC/hkZr7SyEFuvfXWRh5ekiRp2BpWwjKztfpwafXPvta8v1HnlyRJGs3G1SfmS5IkjRaWMEmSpAIsYZIkSQVYwiRJkgqwhEmSJBVgCZMkSSrAEiZJklSAJUySJKkAS5gkSVIBljBJkqQCLGGSJEkFWMIkSZIKsIRJkiQVYAmTJEkqwBImSZJUgCVMkiSpgMjM0jMcsIj4FdBdeo5RpAXYXnqIUcZMaplHPTOpZR71zKSWedQbbibvzMxpAzdOOPTzjIjuzFxQeojRIiI2mkctM6llHvXMpJZ51DOTWuZR72Az8XKkJElSAZYwSZKkAsZqCessPcAoYx71zKSWedQzk1rmUc9MaplHvYPKZEzemC9JkjTWjdV3wiRJksY0S5gkSVIBY6qERcSiiOiOiKci4qrS85QQEV+NiBcj4vF+234rIr4XEf+j+t9/VXLGkRQRx0XE/RHxRET8JCJWVreP50zeGhE/jogt1UyuqW5/V0T8qPr98/cRMbH0rCMpIpoi4tGI+E71+XjPoxIRWyNic0RsrG4bz983b4+I2yPiyYjYFhFnjPM8Tqj+3Xjjz2sRccU4z+RT1Z+pj0fErdWftQf1c2TMlLCIaAK+AnwImAtcFBFzy05VxC3AogHbrgLuzcx3A/dWn48Xu4E/y8y5wOnAJ6t/L8ZzJr8BPpCZJwPzgEURcTrwF8CXM/N44GXgsoIzlrAS2Nbv+XjPA6AjM+f1+5yj8fx9cz2wPjNnAyfT93dl3OaRmd3VvxvzgPnA68A/ME4ziYgZwApgQWaeCDQBf8hB/hwZMyUMeB/wVGb+NDN3ArcBHy4804jLzA3ALwds/jDwN9XHfwOcP6JDFZSZP8/MR6qPf0XfD84ZjO9MMjN7qk+PqP5J4APA7dXt4yqTiJgJnAvcVH0ejOM8BjEuv28iYiqwELgZIDN3ZuYrjNM89uGDwP/MzP/F+M5kAjApIiYAbwN+zkH+HBlLJWwG8Ey/589WtwnekZk/rz5+HnhHyWFKiYhW4BTgR4zzTKqX3jYDLwLfA/4n8Epm7q4uGW/fP9cBnwH2Vp8fxfjOA/qK+T0RsSkillW3jdfvm3cBLwHrqpesb4qIyYzfPAb6Q+DW6uNxmUlmPgd8EfgZfeXrVWATB/lzZCyVMA1D9n3myLj73JGIaAbuAK7IzNf67xuPmWTmnuplhJn0vYs8u/BIxUTEecCLmbmp9CyjzJmZeSp9t3h8MiIW9t85zr5vJgCnAv8lM08BehlwmW2c5fEvqvc4/R7w3wfuG0+ZVO99+zB9hf1YYDL1twYdsLFUwp4Djuv3fGZ1m+CFiJgOUP3vi4XnGVERcQR9BezrmfnN6uZxnckbqpdU7gfOAN5efRsdxtf3z28DvxcRFfpuY/gAfff/jNc8gH/5f/Zk5ov03evzPsbv982zwLOZ+aPq89vpK2XjNY/+PgQ8kpkvVJ+P10zOAp7OzJcycxfwTfp+thzUz5GxVMIeBt5d/ZcIE+l7e/TbhWcaLb4NfLz6+OPAPxacZURV7+25GdiWmV/qt2s8ZzItIt5efTwJOJu+e+XuBy6sLhs3mWTm1Zk5MzNb6fu5cV9mLmac5gEQEZMjYsobj4FzgMcZp983mfk88ExEnFDd9EHgCcZpHgNcxP+5FAnjN5OfAadHxNuq/7vzxt+Rg/o5MqY+MT8ifpe+ezuagK9m5p8XHmnERcStQDvQArwA/AfgW8Do2xRgAAACoElEQVR/A2YB/wv4g8wcePP+YSkizgS+D2zl/9zv81n67gsbr5m8l74bRJvo+z9a/y0zvxARbfS9E/RbwKPARzPzN+UmHXkR0Q5cmZnnjec8ql/7P1SfTgC+kZl/HhFHMX6/b+bR9w83JgI/BS6l+v3DOMwD/qWg/wxoy8xXq9vG89+Ra4CP0Pev8h8FltJ3D9ib/jkypkqYJEnS4WIsXY6UJEk6bFjCJEmSCrCESZIkFWAJkyRJKsASJkmSVMCEoZdI0ugXEXvo+6iSN5yfmZVC40jSkPyICkmHhYjoyczmETzfhH6/M06SDpiXIyWNCxExPSI2RMTmiHg8It5f3b4oIh6JiC0RcW91229FxLci4rGIeKj6AbhExOcj4msR8UPga9XfTnBHRDxc/fPbBb9ESWOMlyMlHS4mRcTm6uOnM/OCAfsvBr5b/WT4JuBtETENuBFYmJlPR8RvVddeAzyamedHxAeAvwXmVffNpe+XX++IiG8AX87MH0TELOC7wJwGfo2SDiOWMEmHix2ZOW+Q/Q8DX63+wvdvZebm6q8x2pCZTwP0+/UrZwL/rrrtvog4KiKOrO77dmbuqD4+C5jb96vkADgyIpozs+fQfVmSDleWMEnjQmZuiIiFwLnALRHxJeDlN3Go3n6P3wKcnpm/PhQzShpfvCdM0rgQEe8EXsjMG+n7Rc2nAg8BCyPiXdU1b1yO/D6wuLqtHdiema/t47D3AH/a7xyDvRMnSTV8J0zSeNEO/N8RsQvoAf4oM1+KiGXANyPiLcCLwNnA5+m7dPkY8Drw8f0ccwXwleq6CcAG4PKGfhWSDht+RIUkSVIBXo6UJEkqwBImSZJUgCVMkiSpAEuYJElSAZYwSZKkAixhkiRJBVjCJEmSCvj/AS6gcmtdmP0BAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##07. LGBM\n",
        "xgb도 여전히 시간이 오래 걸림. 시간 문제를 해결한 lgbm! lgbm은 균형 트리 분할이 아닌 리프 중심 트리 분할을 사용한다. 비대칭적인 규칙 트리가 생성되는 것. 그래서 하이퍼 파라미터에서 **max_depth를 매우 크게 가지는 등의 특성**이 있다.\n",
        "\n",
        "하이퍼 파라미터 조정은 num_leaves의 개수를 중심으로 min_child_samples, max_depth를 함께 조정하며 모델의 복잡도를 줄이는 방식이 기본 튜닝 방안이다."
      ],
      "metadata": {
        "id": "m3QUXgwZ4pt1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###LGBM 실습 - 위스콘신 유방암 예측"
      ],
      "metadata": {
        "id": "r2-pDHz88t3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dataset=load_breast_cancer()\n",
        "ftr=dataset.data\n",
        "target=dataset.target\n",
        "\n",
        "X_train, X_test, y_train, y_test=train_test_split(ftr, target, test_size=0.2, random_state=156)\n",
        "\n",
        "lgbm=LGBMClassifier(n_estimators=400)\n",
        "\n",
        "#lgbm도 조기 중단이 수행 가능하다!\n",
        "evals=[(X_test, y_test)]\n",
        "lgbm.fit(X_train, y_train, early_stopping_rounds=100, eval_metric='logloss', eval_set=evals, verbose=True)\n",
        "preds=lgbm.predict(X_test)\n",
        "pred_proba=lgbm.predict_proba(X_test)[:,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmFG34xN60_V",
        "outputId": "2cea11d3-f57a-4c30-ce84-f1196e4bb083"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\tvalid_0's binary_logloss: 0.565079\tvalid_0's binary_logloss: 0.565079\n",
            "Training until validation scores don't improve for 100 rounds.\n",
            "[2]\tvalid_0's binary_logloss: 0.507451\tvalid_0's binary_logloss: 0.507451\n",
            "[3]\tvalid_0's binary_logloss: 0.458489\tvalid_0's binary_logloss: 0.458489\n",
            "[4]\tvalid_0's binary_logloss: 0.417481\tvalid_0's binary_logloss: 0.417481\n",
            "[5]\tvalid_0's binary_logloss: 0.385507\tvalid_0's binary_logloss: 0.385507\n",
            "[6]\tvalid_0's binary_logloss: 0.355846\tvalid_0's binary_logloss: 0.355846\n",
            "[7]\tvalid_0's binary_logloss: 0.330897\tvalid_0's binary_logloss: 0.330897\n",
            "[8]\tvalid_0's binary_logloss: 0.306923\tvalid_0's binary_logloss: 0.306923\n",
            "[9]\tvalid_0's binary_logloss: 0.28776\tvalid_0's binary_logloss: 0.28776\n",
            "[10]\tvalid_0's binary_logloss: 0.26917\tvalid_0's binary_logloss: 0.26917\n",
            "[11]\tvalid_0's binary_logloss: 0.250954\tvalid_0's binary_logloss: 0.250954\n",
            "[12]\tvalid_0's binary_logloss: 0.23847\tvalid_0's binary_logloss: 0.23847\n",
            "[13]\tvalid_0's binary_logloss: 0.225865\tvalid_0's binary_logloss: 0.225865\n",
            "[14]\tvalid_0's binary_logloss: 0.215076\tvalid_0's binary_logloss: 0.215076\n",
            "[15]\tvalid_0's binary_logloss: 0.205996\tvalid_0's binary_logloss: 0.205996\n",
            "[16]\tvalid_0's binary_logloss: 0.196091\tvalid_0's binary_logloss: 0.196091\n",
            "[17]\tvalid_0's binary_logloss: 0.186395\tvalid_0's binary_logloss: 0.186395\n",
            "[18]\tvalid_0's binary_logloss: 0.17942\tvalid_0's binary_logloss: 0.17942\n",
            "[19]\tvalid_0's binary_logloss: 0.174727\tvalid_0's binary_logloss: 0.174727\n",
            "[20]\tvalid_0's binary_logloss: 0.168563\tvalid_0's binary_logloss: 0.168563\n",
            "[21]\tvalid_0's binary_logloss: 0.165432\tvalid_0's binary_logloss: 0.165432\n",
            "[22]\tvalid_0's binary_logloss: 0.160356\tvalid_0's binary_logloss: 0.160356\n",
            "[23]\tvalid_0's binary_logloss: 0.155508\tvalid_0's binary_logloss: 0.155508\n",
            "[24]\tvalid_0's binary_logloss: 0.151598\tvalid_0's binary_logloss: 0.151598\n",
            "[25]\tvalid_0's binary_logloss: 0.149861\tvalid_0's binary_logloss: 0.149861\n",
            "[26]\tvalid_0's binary_logloss: 0.149873\tvalid_0's binary_logloss: 0.149873\n",
            "[27]\tvalid_0's binary_logloss: 0.147032\tvalid_0's binary_logloss: 0.147032\n",
            "[28]\tvalid_0's binary_logloss: 0.145077\tvalid_0's binary_logloss: 0.145077\n",
            "[29]\tvalid_0's binary_logloss: 0.139891\tvalid_0's binary_logloss: 0.139891\n",
            "[30]\tvalid_0's binary_logloss: 0.137416\tvalid_0's binary_logloss: 0.137416\n",
            "[31]\tvalid_0's binary_logloss: 0.138393\tvalid_0's binary_logloss: 0.138393\n",
            "[32]\tvalid_0's binary_logloss: 0.135948\tvalid_0's binary_logloss: 0.135948\n",
            "[33]\tvalid_0's binary_logloss: 0.132968\tvalid_0's binary_logloss: 0.132968\n",
            "[34]\tvalid_0's binary_logloss: 0.129697\tvalid_0's binary_logloss: 0.129697\n",
            "[35]\tvalid_0's binary_logloss: 0.131102\tvalid_0's binary_logloss: 0.131102\n",
            "[36]\tvalid_0's binary_logloss: 0.129382\tvalid_0's binary_logloss: 0.129382\n",
            "[37]\tvalid_0's binary_logloss: 0.128044\tvalid_0's binary_logloss: 0.128044\n",
            "[38]\tvalid_0's binary_logloss: 0.127325\tvalid_0's binary_logloss: 0.127325\n",
            "[39]\tvalid_0's binary_logloss: 0.128091\tvalid_0's binary_logloss: 0.128091\n",
            "[40]\tvalid_0's binary_logloss: 0.129045\tvalid_0's binary_logloss: 0.129045\n",
            "[41]\tvalid_0's binary_logloss: 0.127023\tvalid_0's binary_logloss: 0.127023\n",
            "[42]\tvalid_0's binary_logloss: 0.129314\tvalid_0's binary_logloss: 0.129314\n",
            "[43]\tvalid_0's binary_logloss: 0.129175\tvalid_0's binary_logloss: 0.129175\n",
            "[44]\tvalid_0's binary_logloss: 0.128212\tvalid_0's binary_logloss: 0.128212\n",
            "[45]\tvalid_0's binary_logloss: 0.126664\tvalid_0's binary_logloss: 0.126664\n",
            "[46]\tvalid_0's binary_logloss: 0.127662\tvalid_0's binary_logloss: 0.127662\n",
            "[47]\tvalid_0's binary_logloss: 0.126108\tvalid_0's binary_logloss: 0.126108\n",
            "[48]\tvalid_0's binary_logloss: 0.129371\tvalid_0's binary_logloss: 0.129371\n",
            "[49]\tvalid_0's binary_logloss: 0.129573\tvalid_0's binary_logloss: 0.129573\n",
            "[50]\tvalid_0's binary_logloss: 0.130876\tvalid_0's binary_logloss: 0.130876\n",
            "[51]\tvalid_0's binary_logloss: 0.131366\tvalid_0's binary_logloss: 0.131366\n",
            "[52]\tvalid_0's binary_logloss: 0.131336\tvalid_0's binary_logloss: 0.131336\n",
            "[53]\tvalid_0's binary_logloss: 0.13208\tvalid_0's binary_logloss: 0.13208\n",
            "[54]\tvalid_0's binary_logloss: 0.13306\tvalid_0's binary_logloss: 0.13306\n",
            "[55]\tvalid_0's binary_logloss: 0.132342\tvalid_0's binary_logloss: 0.132342\n",
            "[56]\tvalid_0's binary_logloss: 0.134836\tvalid_0's binary_logloss: 0.134836\n",
            "[57]\tvalid_0's binary_logloss: 0.135208\tvalid_0's binary_logloss: 0.135208\n",
            "[58]\tvalid_0's binary_logloss: 0.13328\tvalid_0's binary_logloss: 0.13328\n",
            "[59]\tvalid_0's binary_logloss: 0.134147\tvalid_0's binary_logloss: 0.134147\n",
            "[60]\tvalid_0's binary_logloss: 0.134549\tvalid_0's binary_logloss: 0.134549\n",
            "[61]\tvalid_0's binary_logloss: 0.133202\tvalid_0's binary_logloss: 0.133202\n",
            "[62]\tvalid_0's binary_logloss: 0.135726\tvalid_0's binary_logloss: 0.135726\n",
            "[63]\tvalid_0's binary_logloss: 0.134011\tvalid_0's binary_logloss: 0.134011\n",
            "[64]\tvalid_0's binary_logloss: 0.131493\tvalid_0's binary_logloss: 0.131493\n",
            "[65]\tvalid_0's binary_logloss: 0.134114\tvalid_0's binary_logloss: 0.134114\n",
            "[66]\tvalid_0's binary_logloss: 0.134525\tvalid_0's binary_logloss: 0.134525\n",
            "[67]\tvalid_0's binary_logloss: 0.131412\tvalid_0's binary_logloss: 0.131412\n",
            "[68]\tvalid_0's binary_logloss: 0.12878\tvalid_0's binary_logloss: 0.12878\n",
            "[69]\tvalid_0's binary_logloss: 0.129571\tvalid_0's binary_logloss: 0.129571\n",
            "[70]\tvalid_0's binary_logloss: 0.129671\tvalid_0's binary_logloss: 0.129671\n",
            "[71]\tvalid_0's binary_logloss: 0.129935\tvalid_0's binary_logloss: 0.129935\n",
            "[72]\tvalid_0's binary_logloss: 0.128951\tvalid_0's binary_logloss: 0.128951\n",
            "[73]\tvalid_0's binary_logloss: 0.128977\tvalid_0's binary_logloss: 0.128977\n",
            "[74]\tvalid_0's binary_logloss: 0.127121\tvalid_0's binary_logloss: 0.127121\n",
            "[75]\tvalid_0's binary_logloss: 0.128107\tvalid_0's binary_logloss: 0.128107\n",
            "[76]\tvalid_0's binary_logloss: 0.129796\tvalid_0's binary_logloss: 0.129796\n",
            "[77]\tvalid_0's binary_logloss: 0.131663\tvalid_0's binary_logloss: 0.131663\n",
            "[78]\tvalid_0's binary_logloss: 0.132483\tvalid_0's binary_logloss: 0.132483\n",
            "[79]\tvalid_0's binary_logloss: 0.131578\tvalid_0's binary_logloss: 0.131578\n",
            "[80]\tvalid_0's binary_logloss: 0.130352\tvalid_0's binary_logloss: 0.130352\n",
            "[81]\tvalid_0's binary_logloss: 0.129895\tvalid_0's binary_logloss: 0.129895\n",
            "[82]\tvalid_0's binary_logloss: 0.131587\tvalid_0's binary_logloss: 0.131587\n",
            "[83]\tvalid_0's binary_logloss: 0.132763\tvalid_0's binary_logloss: 0.132763\n",
            "[84]\tvalid_0's binary_logloss: 0.133677\tvalid_0's binary_logloss: 0.133677\n",
            "[85]\tvalid_0's binary_logloss: 0.137552\tvalid_0's binary_logloss: 0.137552\n",
            "[86]\tvalid_0's binary_logloss: 0.136055\tvalid_0's binary_logloss: 0.136055\n",
            "[87]\tvalid_0's binary_logloss: 0.137904\tvalid_0's binary_logloss: 0.137904\n",
            "[88]\tvalid_0's binary_logloss: 0.139524\tvalid_0's binary_logloss: 0.139524\n",
            "[89]\tvalid_0's binary_logloss: 0.138434\tvalid_0's binary_logloss: 0.138434\n",
            "[90]\tvalid_0's binary_logloss: 0.138402\tvalid_0's binary_logloss: 0.138402\n",
            "[91]\tvalid_0's binary_logloss: 0.139384\tvalid_0's binary_logloss: 0.139384\n",
            "[92]\tvalid_0's binary_logloss: 0.139642\tvalid_0's binary_logloss: 0.139642\n",
            "[93]\tvalid_0's binary_logloss: 0.138006\tvalid_0's binary_logloss: 0.138006\n",
            "[94]\tvalid_0's binary_logloss: 0.141612\tvalid_0's binary_logloss: 0.141612\n",
            "[95]\tvalid_0's binary_logloss: 0.142319\tvalid_0's binary_logloss: 0.142319\n",
            "[96]\tvalid_0's binary_logloss: 0.145095\tvalid_0's binary_logloss: 0.145095\n",
            "[97]\tvalid_0's binary_logloss: 0.141542\tvalid_0's binary_logloss: 0.141542\n",
            "[98]\tvalid_0's binary_logloss: 0.144993\tvalid_0's binary_logloss: 0.144993\n",
            "[99]\tvalid_0's binary_logloss: 0.147936\tvalid_0's binary_logloss: 0.147936\n",
            "[100]\tvalid_0's binary_logloss: 0.147432\tvalid_0's binary_logloss: 0.147432\n",
            "[101]\tvalid_0's binary_logloss: 0.149689\tvalid_0's binary_logloss: 0.149689\n",
            "[102]\tvalid_0's binary_logloss: 0.153542\tvalid_0's binary_logloss: 0.153542\n",
            "[103]\tvalid_0's binary_logloss: 0.154556\tvalid_0's binary_logloss: 0.154556\n",
            "[104]\tvalid_0's binary_logloss: 0.155458\tvalid_0's binary_logloss: 0.155458\n",
            "[105]\tvalid_0's binary_logloss: 0.159357\tvalid_0's binary_logloss: 0.159357\n",
            "[106]\tvalid_0's binary_logloss: 0.160176\tvalid_0's binary_logloss: 0.160176\n",
            "[107]\tvalid_0's binary_logloss: 0.163369\tvalid_0's binary_logloss: 0.163369\n",
            "[108]\tvalid_0's binary_logloss: 0.163494\tvalid_0's binary_logloss: 0.163494\n",
            "[109]\tvalid_0's binary_logloss: 0.161111\tvalid_0's binary_logloss: 0.161111\n",
            "[110]\tvalid_0's binary_logloss: 0.16332\tvalid_0's binary_logloss: 0.16332\n",
            "[111]\tvalid_0's binary_logloss: 0.1663\tvalid_0's binary_logloss: 0.1663\n",
            "[112]\tvalid_0's binary_logloss: 0.166363\tvalid_0's binary_logloss: 0.166363\n",
            "[113]\tvalid_0's binary_logloss: 0.169834\tvalid_0's binary_logloss: 0.169834\n",
            "[114]\tvalid_0's binary_logloss: 0.166509\tvalid_0's binary_logloss: 0.166509\n",
            "[115]\tvalid_0's binary_logloss: 0.165823\tvalid_0's binary_logloss: 0.165823\n",
            "[116]\tvalid_0's binary_logloss: 0.167059\tvalid_0's binary_logloss: 0.167059\n",
            "[117]\tvalid_0's binary_logloss: 0.169086\tvalid_0's binary_logloss: 0.169086\n",
            "[118]\tvalid_0's binary_logloss: 0.170012\tvalid_0's binary_logloss: 0.170012\n",
            "[119]\tvalid_0's binary_logloss: 0.168639\tvalid_0's binary_logloss: 0.168639\n",
            "[120]\tvalid_0's binary_logloss: 0.16907\tvalid_0's binary_logloss: 0.16907\n",
            "[121]\tvalid_0's binary_logloss: 0.16918\tvalid_0's binary_logloss: 0.16918\n",
            "[122]\tvalid_0's binary_logloss: 0.170233\tvalid_0's binary_logloss: 0.170233\n",
            "[123]\tvalid_0's binary_logloss: 0.165655\tvalid_0's binary_logloss: 0.165655\n",
            "[124]\tvalid_0's binary_logloss: 0.16695\tvalid_0's binary_logloss: 0.16695\n",
            "[125]\tvalid_0's binary_logloss: 0.170955\tvalid_0's binary_logloss: 0.170955\n",
            "[126]\tvalid_0's binary_logloss: 0.168916\tvalid_0's binary_logloss: 0.168916\n",
            "[127]\tvalid_0's binary_logloss: 0.172316\tvalid_0's binary_logloss: 0.172316\n",
            "[128]\tvalid_0's binary_logloss: 0.173734\tvalid_0's binary_logloss: 0.173734\n",
            "[129]\tvalid_0's binary_logloss: 0.174309\tvalid_0's binary_logloss: 0.174309\n",
            "[130]\tvalid_0's binary_logloss: 0.176719\tvalid_0's binary_logloss: 0.176719\n",
            "[131]\tvalid_0's binary_logloss: 0.176591\tvalid_0's binary_logloss: 0.176591\n",
            "[132]\tvalid_0's binary_logloss: 0.180168\tvalid_0's binary_logloss: 0.180168\n",
            "[133]\tvalid_0's binary_logloss: 0.179856\tvalid_0's binary_logloss: 0.179856\n",
            "[134]\tvalid_0's binary_logloss: 0.179251\tvalid_0's binary_logloss: 0.179251\n",
            "[135]\tvalid_0's binary_logloss: 0.18315\tvalid_0's binary_logloss: 0.18315\n",
            "[136]\tvalid_0's binary_logloss: 0.184656\tvalid_0's binary_logloss: 0.184656\n",
            "[137]\tvalid_0's binary_logloss: 0.187475\tvalid_0's binary_logloss: 0.187475\n",
            "[138]\tvalid_0's binary_logloss: 0.188721\tvalid_0's binary_logloss: 0.188721\n",
            "[139]\tvalid_0's binary_logloss: 0.188542\tvalid_0's binary_logloss: 0.188542\n",
            "[140]\tvalid_0's binary_logloss: 0.18817\tvalid_0's binary_logloss: 0.18817\n",
            "[141]\tvalid_0's binary_logloss: 0.185899\tvalid_0's binary_logloss: 0.185899\n",
            "[142]\tvalid_0's binary_logloss: 0.185452\tvalid_0's binary_logloss: 0.185452\n",
            "[143]\tvalid_0's binary_logloss: 0.186084\tvalid_0's binary_logloss: 0.186084\n",
            "[144]\tvalid_0's binary_logloss: 0.185302\tvalid_0's binary_logloss: 0.185302\n",
            "[145]\tvalid_0's binary_logloss: 0.187856\tvalid_0's binary_logloss: 0.187856\n",
            "[146]\tvalid_0's binary_logloss: 0.190334\tvalid_0's binary_logloss: 0.190334\n",
            "[147]\tvalid_0's binary_logloss: 0.192769\tvalid_0's binary_logloss: 0.192769\n",
            "Early stopping, best iteration is:\n",
            "[47]\tvalid_0's binary_logloss: 0.126108\tvalid_0's binary_logloss: 0.126108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 교재에 따르면 get_clf_eval(y_test, preds, pred_proba)로 얻은 정확도는 0.9474로 xgb보다는 살짝 낮으나 큰 의미는 없다.\n",
        "- xgb와 동일한 방식으로 피처 중요도 시각화도 가능하다."
      ],
      "metadata": {
        "id": "3A0cF3vR77VV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##08. 분류 실습 - 캐글 산탄데르 고객 만족 예측 (간단히 보기)\n",
        "- 만족/불만족이 비대칭인 데이터이므로 정확도보단 ROC-AUC가 더 적합하겠군.\n",
        "\n",
        "**1. 데이터 전처리**\n",
        "- 모든 피처가 숫자형, null은 없음\n",
        "- 하지만 불만족이 4%에 불과함.\n",
        "- var3 피처에는 null을 -999999로 넣은 값이 있음 -> 그 피처에서 최빈값인 2로 대체\n",
        "- X_features와 y_labels 저장 후 train_test_split 진행. 이 때 **불만족 비율이 유지되었는지 꼭 확인**하기!\n",
        "\n",
        "**2. XGB와 LGBM 학습하고 하이퍼 파라미터 튜닝**\n",
        "\n"
      ],
      "metadata": {
        "id": "RCIDXeyL4sIP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##09. 분류 실습 - 캐글 신용카드 사기 검출 (자세히 보기)\n",
        "- 굉장히 불균형한 데이터!! 언더 샘플링 또는 오버 샘플링이 필요해보인다. SMOTE를 사용할 것이다.\n",
        "\n"
      ],
      "metadata": {
        "id": "9UdJVcSLAzll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#실습에 앞서 get_clf_eval 정의해두기!\n",
        "\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score\n",
        "from sklearn.metrics import recall_score, f1_score, roc_auc_score\n",
        "def get_clf_eval(y_test, pred=None, pred_proba=None):\n",
        "  confusion=confusion_matrix(y_test, pred)\n",
        "  accuracy=accuracy_score(y_test, pred)\n",
        "  precision=precision_score(y_test, pred)\n",
        "  recall=recall_score(y_test, pred)\n",
        "  f1=f1_score(y_test, pred)\n",
        "  roc_auc=roc_auc_score(y_test, pred_proba)\n",
        "  print('오차 행렬')\n",
        "  print(confusion)\n",
        "  print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1:{3:.4f}, AUC:{4:.4f}'.format(accuracy, precision, recall, f1, roc_auc))"
      ],
      "metadata": {
        "id": "T2qvWa2pGmGt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**데이터 일차 가공**"
      ],
      "metadata": {
        "id": "LC5CNHCmCeWH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "\n",
        "card_df=pd.read_csv('creditcard.csv')\n",
        "\n",
        "#결측값은 없고 모두 숫자형이다\n",
        "#Time 피처는 의미 없으므로 제거할 것임\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# 인자로 입력 받은 dF를 복사한 뒤, time 칼럼 삭제하고 복사된 df를 반환하는 함수 만들자\n",
        "def get_preprocessed_df(df=None):\n",
        "  df_copy=df.copy()\n",
        "  df_copy.drop('Time', axis=1, inplace=True)\n",
        "  return df_copy\n",
        "\n",
        "#사전 데이터 가공 후 학습과 테스트 데이터 세트를 반환하는 함수 만들자\n",
        "def get_train_test_dataset(df=None):\n",
        "  df_copy=get_preprocessed_df(df)\n",
        "  X_features=df_copy.iloc[:,:-1]\n",
        "  y_target=df_copy.iloc[:,-1]\n",
        "  X_train, X_test, y_train, y_test=train_test_split(X_features, y_target, test_size=0.3, random_state=0, stratify=y_target)\n",
        "  return X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train, X_test, y_train, y_test=get_train_test_dataset(card_df)"
      ],
      "metadata": {
        "id": "0Tyya9gVC3RT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 비율 문제 없이 잘 분할 되었는지 확인하기! -> 잘 분할됨."
      ],
      "metadata": {
        "id": "kOZrywlCFcHz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**일차 가공한 모델 학습/예측/평가**"
      ],
      "metadata": {
        "id": "SYAqLGI5GMUX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 로지스틱 회귀"
      ],
      "metadata": {
        "id": "9ia3YWukGyBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_clf=LogisticRegression()\n",
        "lr_clf.fit(X_train, y_train)\n",
        "lr_pred=lr_clf.predict(X_test)\n",
        "lr_pred_proba=lr_clf.predict_proba(X_test)[:,1]\n",
        "\n",
        "get_clf_eval(y_test, lr_pred, lr_pred_proba)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MgVo8vKOGwbP",
        "outputId": "898869e8-3cc5-4ebd-ee3f-54cd1bfed14a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오차 행렬\n",
            "[[85281    14]\n",
            " [   60    88]]\n",
            "정확도: 0.9991, 정밀도: 0.8627, 재현율: 0.5946, F1:0.7040, AUC:0.9639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 재현율이 0.6 정도, AUC가 0.96 정도."
      ],
      "metadata": {
        "id": "tfSKswtLHWGS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. LGBM"
      ],
      "metadata": {
        "id": "HU-KlzEYHbc4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#앞으로 몇 번 반복할거니까 학습/예측/평가를 수행해주는 함수를 생성하자.\n",
        "def get_model_train_eval(model, ftr_train=None, ftr_test=None, tgt_train=None, tgt_test=None):\n",
        "  model.fit(ftr_train, tgt_train)\n",
        "  pred=model.predict(ftr_test)\n",
        "  pred_proba=model.predict_proba(ftr_test)[:,1]\n",
        "  get_clf_eval(tgt_test, pred, pred_proba)"
      ],
      "metadata": {
        "id": "f0BrF2QLHckQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#이제 lgbm 해보자\n",
        "from lightgbm import LGBMClassifier\n",
        "\n",
        "lgbm_clf=LGBMClassifier(n_estimators=1000, num_leaves=64, n_jobs=-1, boost_from_average=False) #불균형한 분포를 가지므로 boost_from_average=False로 설정해야한다\n",
        "get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmANEuNQI2v2",
        "outputId": "3cba4e95-b0d4-4928-dd62-b5f6e0fe13f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오차 행렬\n",
            "[[85289     6]\n",
            " [   36   112]]\n",
            "정확도: 0.9995, 정밀도: 0.9492, 재현율: 0.7568, F1:0.8421, AUC:0.9797\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 재현율이 0.75 정도, AUC가 0.97 정도로 로지스틱 회귀보다는 괜찮아보인다."
      ],
      "metadata": {
        "id": "lXCYfuMfJXSW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. XGB\n",
        "- 교재에는 없지만 가능한지 돌려보자"
      ],
      "metadata": {
        "id": "B4neLXwpJuYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#from xgboost import XGBClassifier\n",
        "\n",
        "#xgb_clf=XGBClassifier(n_estimators=1000,learning_rate=0.02, max_depth=7, min_child_weight=1, colsample_bytree=0.75, reg_alpha=0.03)\n",
        "#get_model_train_eval(xgb_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)"
      ],
      "metadata": {
        "id": "fofD0h4cKMEq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 시간이 너무 오래 걸린다. 데이터가 매우 커서 그런듯 하다. 만약 xgb를 사용하면 이런식으로 사용할 수 있다. 코드는 산탄데르 고객 만족 데이터 실습에서 참고."
      ],
      "metadata": {
        "id": "xKXtBT2kLFFn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**데이터 분포도 변환 후 학습/예측/평가**\n",
        "- Amount 피처가 꼬리가 긴 형태의 분포 곡선을 가지고 있다. 변환해볼까."
      ],
      "metadata": {
        "id": "6_Ci2AjZLU2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**정규 분포 형태로?**"
      ],
      "metadata": {
        "id": "1s9xV9MqN5t4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#아까 정의했던 함수 StandardScaler로 amount 피처 값도 변환해주는 로직으로 수정하자!\n",
        "\n",
        "def get_preprocessed_df(df=None):\n",
        "  df_copy=df.copy()\n",
        "  scaler=StandardScaler()\n",
        "  amount_n=scaler.fit_transform(df_copy['Amount'].values.reshape(-1,1))\n",
        "  #변환된 amount를 Amount_Scaled로 피처명 변경 후 DF 맨 앞 칼럼으로 입력\n",
        "  df_copy.insert(0, 'Amount_Scaled', amount_n)\n",
        "  #기존 time과 amount 피처 삭제\n",
        "  df_copy.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
        "  return df_copy"
      ],
      "metadata": {
        "id": "nWopT1yHLo1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Amount를 정규 분포 형태로 변환 후 학습/예측/평가 수행하자\n",
        "X_train, X_test, y_train, y_test=get_train_test_dataset(card_df)"
      ],
      "metadata": {
        "id": "eMvcFZg6MwAj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 로지스틱 회귀"
      ],
      "metadata": {
        "id": "cUwlKPR3M-nZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_clf=LogisticRegression()\n",
        "get_model_train_eval(lr_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VSrNCxeJM_84",
        "outputId": "5a6d9070-3acf-456e-dd43-531ef0190666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오차 행렬\n",
            "[[85281    14]\n",
            " [   58    90]]\n",
            "정확도: 0.9992, 정밀도: 0.8654, 재현율: 0.6081, F1:0.7143, AUC:0.9702\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. LGBM"
      ],
      "metadata": {
        "id": "s5VjK8u0NL22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_clf=LGBMClassifier(n_estimatiors=1000, num_leaves=64, n_jobs=-1)\n",
        "get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qk_bqmLfNM0q",
        "outputId": "bf631502-ff7a-4726-f0a4-1c86e1db5d46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오차 행렬\n",
            "[[85151   144]\n",
            " [   85    63]]\n",
            "정확도: 0.9973, 정밀도: 0.3043, 재현율: 0.4257, F1:0.3549, AUC:0.6085\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- StandardScaler 성능이 딱히 좋지 않아보임"
      ],
      "metadata": {
        "id": "CJNSH3EaNvIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**로그 변환?**"
      ],
      "metadata": {
        "id": "7687BvUoOATL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#amount 피처 값 로그 변환도 해주는 로직으로 수정하자!\n",
        "\n",
        "def get_preprocessed_df(df=None):\n",
        "  df_copy=df.copy()\n",
        "  amount_n=np.log1p(df_copy['Amount'])\n",
        "  #변환된 amount를 Amount_Scaled로 피처명 변경 후 DF 맨 앞 칼럼으로 입력\n",
        "  df_copy.insert(0, 'Amount_Scaled', amount_n)\n",
        "  #기존 time과 amount 피처 삭제\n",
        "  df_copy.drop(['Time', 'Amount'], axis=1, inplace=True)\n",
        "  return df_copy"
      ],
      "metadata": {
        "id": "vnkFrL03OGeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Amount를 로그 변환 후 학습/예측/평가 수행하자\n",
        "X_train, X_test, y_train, y_test=get_train_test_dataset(card_df)"
      ],
      "metadata": {
        "id": "y7EumuQ4ObzI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 로지스틱 회귀"
      ],
      "metadata": {
        "id": "2k_wrzteOqQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_clf=LogisticRegression()\n",
        "get_model_train_eval(lr_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d43B0rOXOrVN",
        "outputId": "122689b0-7454-483f-9898-eebec433fcc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오차 행렬\n",
            "[[85283    12]\n",
            " [   59    89]]\n",
            "정확도: 0.9992, 정밀도: 0.8812, 재현율: 0.6014, F1:0.7149, AUC:0.9727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. LGBM"
      ],
      "metadata": {
        "id": "kzbeIOjxOrm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_clf=LGBMClassifier(n_estimatiors=1000, num_leaves=64, n_jobs=-1)\n",
        "get_model_train_eval(lgbm_clf, ftr_train=X_train, ftr_test=X_test, tgt_train=y_train, tgt_test=y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JpYI3WBFOu2o",
        "outputId": "89ad969c-2c44-4649-93a3-22964113a041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "오차 행렬\n",
            "[[85106   189]\n",
            " [  144     4]]\n",
            "정확도: 0.9961, 정밀도: 0.0207, 재현율: 0.0270, F1:0.0235, AUC:0.2758\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 심하게 왜곡된 데이터는 로그 변환이 괜찮아보임"
      ],
      "metadata": {
        "id": "zvFVj7jgO7a_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**이상치 제거 후 학습/예측/평가**\n",
        "- 이상치를 제거하면 성능이 크게 향상됨"
      ],
      "metadata": {
        "id": "fOPDZdaHO-g6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**SMOTE 오버 샘플링 적용 후 학습/예측/평가**\n",
        "- 반드시 학습 데이터 세트만 오버 샘플링을 해야 한다는 점을 주의"
      ],
      "metadata": {
        "id": "hr22VwyvPTop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQtLn8UDQKMf",
        "outputId": "3ea0ba0e-88c7-4a63-fc1f-623375c78bf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.8/dist-packages (0.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.8/dist-packages (from imbalanced-learn) (1.7.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "smote=SMOTE(random_state=0)\n",
        "X_train_over, y_train_over=smote.fit_sample(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "y0g6cK8IPfzc",
        "outputId": "fdacfde7-f81d-4875-d9cb-4a463a3f4d16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-1444e6d11652>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msmote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSMOTE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_train_over\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_over\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msmote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_sample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'SMOTE' object has no attribute 'fit_sample'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- smote 적용 전 학습 데이터 세트보다 2배 가까이 증식됨\n",
        "- 그리고 smote를 적용하니 0과 1의 분포가 동일하게 생성되었다."
      ],
      "metadata": {
        "id": "ExmJ8HnIQbhm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. 로지스틱 회귀"
      ],
      "metadata": {
        "id": "AFhr3OJ7RDa4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_clf=LogisticRegression()\n",
        "get_model_train_eval(lr_clf, ftr_train=X_train_over, ftr_test=X_test, tgt_train=y_train_over, tgt_test=y_test)"
      ],
      "metadata": {
        "id": "4RRVPknUQpeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 로지스틱의 경우 재현율은 크게 증가하나 정밀도가 너무 떨어짐. 예측을 지나치게 1로 한 것... -> smote로는 로지스틱은 사용 불가."
      ],
      "metadata": {
        "id": "c-AUPMiKRViU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. LGBM"
      ],
      "metadata": {
        "id": "jJHYmKh3RtZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lgbm_clf=LGBMClassifier(n_estimatiors=1000, num_leaves=64, n_jobs=-1, boost_from_average=False)\n",
        "get_model_train_eval(lgbm_clf, ftr_train=X_train_over, ftr_test=X_test, tgt_train=y_train_over, tgt_test=y_test)"
      ],
      "metadata": {
        "id": "RavNT0LdRuzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이상치만 제거한 경우보다 재현율이 높아지기도 함! **SMOTE 적용시 재현율은 높아지나 정밀도는 낮아지는 것이 일반적**. "
      ],
      "metadata": {
        "id": "EpeDTUoASBjN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##10. 스태킹 앙상블\n",
        "- 여러 알고리즘을 결합한다는 것에서 배깅 및 부스팅과 공통점.\n",
        "- 하지만 최종 메타 데이터 세트를 만들어 별도의 머신러닝 알고리즘으로 최종 학습을 수행하고 테스트 데이터를 기반으로 다시 최종 예측을 진행하는 방식.\n",
        "- 현실에서는 잘 쓰이진 않지만 조금이라도 더 성능을 향상하고 싶을 때 사용,,"
      ],
      "metadata": {
        "id": "e93K3sp9SLZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###기본 스태킹 모델"
      ],
      "metadata": {
        "id": "4LL8YX3ZvGMG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "#여기서 불러오는 애들이 개별 모델이 될 것임\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "#그리고 최종 모델은 로지스틱 회귀가 될 것임\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "cancer_data=load_breast_cancer()\n",
        "\n",
        "X_data=cancer_data.data\n",
        "y_label=cancer_data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_data, y_label, test_size=0.2, random_state=0)"
      ],
      "metadata": {
        "id": "Uke-TwNBvMZv"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#개별 머신러닝 모델 생성\n",
        "knn_clf=KNeighborsClassifier(n_neighbors=4)\n",
        "rf_clf=RandomForestClassifier(n_estimators=100, random_state=0)\n",
        "dt_clf=DecisionTreeClassifier()\n",
        "ada_clf=AdaBoostClassifier(n_estimators=100)\n",
        "\n",
        "#스태킹으로 만들어진 데이터 세트를 학습, 예측할 최종 모델\n",
        "lr_final=LogisticRegression(C=10)"
      ],
      "metadata": {
        "id": "6IKqDaVRwca5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#개별 모델들 학습\n",
        "knn_clf.fit(X_train, y_train)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "dt_clf.fit(X_train, y_train)\n",
        "ada_clf.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ondpb9CP7PBM",
        "outputId": "b65889c7-263f-4b65-80b9-966b917a2043"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AdaBoostClassifier(n_estimators=100)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#학습된 개별 모델들이 각자 반환하는 예측 데이터를 생성하고 개별 모델의 정확도 측정\n",
        "knn_pred=knn_clf.predict(X_test)\n",
        "rf_pred=rf_clf.predict(X_test)\n",
        "dt_pred=dt_clf.predict(X_test)\n",
        "ada_pred=ada_clf.predict(X_test)\n",
        "\n",
        "print('KNN 정확도: {0:.4f}'.format(accuracy_score(y_test, knn_pred)))\n",
        "print('RF 정확도: {0:.4f}'.format(accuracy_score(y_test, rf_pred)))\n",
        "print('DT 정확도: {0:.4f}'.format(accuracy_score(y_test, dt_pred)))\n",
        "print('ADA 정확도: {0:.4f}'.format(accuracy_score(y_test, ada_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJhwMt297WrL",
        "outputId": "de8ae96b-8c90-4874-8307-b09c909b3c1b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN 정확도: 0.9211\n",
            "RF 정확도: 0.9649\n",
            "DT 정확도: 0.9123\n",
            "ADA 정확도: 0.9561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이렇게 생성된 예측 데이터를 칼럼 레벨로 옆으로 붙여 피처 값으로 만들어 최종 모델인 로지스틱 회귀에서 다시 학습 데이터로 사용하는 것!"
      ],
      "metadata": {
        "id": "KBylhn2o71sF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred=np.array([knn_pred, rf_pred, dt_pred, ada_pred])\n",
        "pred=np.transpose(pred)\n",
        "\n",
        "lr_final.fit(pred, y_test)\n",
        "final=lr_final.predict(pred)\n",
        "\n",
        "print('최종 메타 모델의 예측 정확도: {0:.4f}'.format(accuracy_score(y_test, final)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyQS9sHJ7_E2",
        "outputId": "875c8921-52e9-44ec-ac1c-786bd2682514"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "최종 메타 모델의 예측 정확도: 0.9737\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 확실히 위에 있던 개별 모델들보다 향상되었다."
      ],
      "metadata": {
        "id": "NLaOjlQ78WY9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###CV 세트 기반의 스태킹\n",
        "- 과적합 개선 위함.\n",
        "- 최종 모델을 위한 데이터 세트를 만들 때 교차 검증 기반으로 예측된 결과 데이터 세트를 이용"
      ],
      "metadata": {
        "id": "0BlABOJw8fCS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**스텝 1** : 개별 모델이 메타 모델을 위한 학습용 데이터와 테스트용 데이터를 생성"
      ],
      "metadata": {
        "id": "qa2dIW7q8htG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "#개별 기반 모델에서 최종 메타 모델이 사용할 학습 및 테스트 데이터를 생성하기 위한 함수\n",
        "def get_stacking_base_datasets(model, X_train_n, y_train_n, X_test_n, n_folds):\n",
        "  #지정된 n_folds 값으로 KFold 생성\n",
        "  kf=KFold(n_splits=n_folds, shuffle=True, random_state=0)\n",
        "  #추후에 메타 모델이 사용할 학습 데이터 반환을 위한 넘파이 배열 초기화\n",
        "  train_fold_pred=np.zeros((X_train_n.shape[0], 1))\n",
        "  test_pred=np.zeros((X_test_n.shape[0], n_folds))\n",
        "  print(model.__class__.__name__, 'model 시작')\n",
        "\n",
        "  for folder_counter, (train_index, valid_index) in enumerate(kf.split(X_train_n)):\n",
        "    #입력된 학습 데이터에서 기반 모델이 학습/예측할 폴드 데이터 세트 추출\n",
        "    print('\\t 폴드 세트: ', folder_counter, '시작')\n",
        "    X_tr=X_train_n[train_index]\n",
        "    y_tr=y_train_n[train_index]\n",
        "    X_te=X_test_n[valid_index]\n",
        "\n",
        "    #폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행\n",
        "    model.fit(X_tr, y_tr)\n",
        "    #폴드 세트 내부에서 다시 만들어진 검증 데이터로 기반 모델 예측 후 데이터 저장\n",
        "    train_fold_pred[valid_index, :]=model.predict(X_te).reshape(-1,1)\n",
        "    #입력된 원본 테스트 데이터를 폴드 세트 내 학습된 기반 모델에서 예측 후 데이터 저장\n",
        "    test_pred[:, folder_counter]=model.predict(X_test_n)\n",
        "\n",
        "  #폴드 세트 내에서 원본 테스트 데이터 세트를 예측한 데이터를 평균하여 테스트 데이터로 생성\n",
        "  test_pred_mean=np.mean(test_pred, axis=1).reshape(-1,1)\n",
        "\n",
        "  #train_fold_pred는 최종 메타 모델이 사용하는 학습 데이터, test_pred_mean은 테스트 데이터\n",
        "  return train_fold_pred, test_pred_mean"
      ],
      "metadata": {
        "id": "lK13IiHy9Zqr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn_train, knn_test=get_stacking_base_datasets(knn_clf, X_train, y_train, X_test, 7)\n",
        "rf_train, rf_test=get_stacking_base_datasets(rf_clf, X_train, y_train, X_test, 7)\n",
        "dt_train, dt_test=get_stacking_base_datasets(dt_clf, X_train, y_train, X_test, 7)\n",
        "ada_train, ada_test=get_stacking_base_datasets(ada_clf, X_train, y_train, X_test, 7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "qmJubKx__QH-",
        "outputId": "147fe957-716f-4a76-96b2-2785649054e5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNeighborsClassifier model 시작\n",
            "\t 폴드 세트:  0 시작\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-086d32bedc3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mknn_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mknn_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_stacking_base_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrf_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_stacking_base_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrf_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdt_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_stacking_base_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdt_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mada_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mada_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_stacking_base_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mada_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-ed5c4800b511>\u001b[0m in \u001b[0;36mget_stacking_base_datasets\u001b[0;34m(model, X_train_n, y_train_n, X_test_n, n_folds)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mX_tr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train_n\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0my_tr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_train_n\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mX_te\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test_n\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalid_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#폴드 세트 내부에서 다시 만들어진 학습 데이터로 기반 모델의 학습 수행\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: index 118 is out of bounds for axis 0 with size 114"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**스텝 2** : 각 모델별 학습 데이터와 테스트 데이터를 합치기만 하면 된다"
      ],
      "metadata": {
        "id": "H0Tfh_O4_ugz"
      }
    }
  ]
}
